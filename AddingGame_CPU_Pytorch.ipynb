{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emm32449/MCTS-in-Python/blob/main/AddingGame_CPU_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAZmLtNwwWoM"
      },
      "source": [
        "The game is a simple adding game. The game starts at 0 and players can make moves by adding 1, 2, or 3 to the current state. The goal is to reach exactly 10. If a player’s move results in a state exceeding 10, they receive a negative reward. If the state is less than 10, the reward is based on how close the state is to 10. The game resets once it reaches or exceeds 10."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "x0QYmzhw8vvl"
      },
      "outputs": [],
      "source": [
        "# Assume we have a simple game state\n",
        "class GameState:\n",
        "    def __init__(self, state):\n",
        "        self.state = state\n",
        "\n",
        "    def __str__(self):\n",
        "        return str(self.state)\n",
        "\n",
        "    def get_legal_moves(self):\n",
        "        return [1, 2, 3]\n",
        "\n",
        "    def get_initial_state(self):\n",
        "        return GameState(0)\n",
        "\n",
        "    def make_move(self, move):\n",
        "        return GameState(self.state + move)\n",
        "\n",
        "    def is_terminal(self):\n",
        "        return self.state >= 10\n",
        "\n",
        "    def get_reward(self):\n",
        "        # Give a positive reward if the state is exactly 10\n",
        "        if self.state == 10:\n",
        "            return 1\n",
        "        # Give a negative reward if the state exceeds 10\n",
        "        elif self.state > 10:\n",
        "            return -1\n",
        "        # Give a reward based on how close the state is to 10\n",
        "        else:\n",
        "            return 1 - abs(self.state - 10) / 10\n",
        "\n",
        "    def reset(self):\n",
        "        self.state = 0\n",
        "\n",
        "    def copy(self):\n",
        "        return GameState(self.state)\n",
        "\n",
        "    def to_array(self):\n",
        "        return [self.state]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFNyawMAyaHJ"
      },
      "source": [
        "Alpha Go Zero uses a variant of Monte Carlo Tree Search (MCTS) within its training loop. Starting from the root node, which represents the current game state, it traverses the tree until it reaches a leaf node. This game state is passed through the neural network, which outputs a vector of move probabilities and a scalar estimating the expected outcome. The leaf node is then expanded, with each legal move becoming a new child node. The move probabilities output by the network initialize the prior probabilities of selecting each child node in future simulations. The estimated value output by the network is backpropagated up the tree, updating the value estimates of all nodes along the traversed path.\n",
        "\n",
        "This process is repeated for many simulations, with the Upper Confidence Bound (UCB) formula guiding the selection of nodes during tree traversal. The UCB formula balances exploration and exploitation, taking into account both the value of the node and the prior probability of the node, as well as the number of times the node has been visited. After a large number of simulations, the move leading to the child node with the highest visit count from the root is selected as the next action. This procedure allows AlphaGo Zero to effectively learn a policy favoring high-value actions and a value function predicting the game outcome."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sOOxRknh73dp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# Normalize GameState Data\n",
        "max_state_value = 15  # Initialize with a known max value or a reasonable estimate\n",
        "\n",
        "def prepare_data(state):\n",
        "    global max_state_value\n",
        "    max_state_value = max(max_state_value, max(state))  # Update the max value if the current state is larger\n",
        "    normalized_state = [s / max_state_value for s in state]\n",
        "    return normalized_state\n",
        "\n",
        "class Node:\n",
        "    def __init__(self, game_state, policy, parent=None, move=None):\n",
        "        self.game_state = game_state\n",
        "        self.policy = policy\n",
        "        self.parent = parent\n",
        "        self.move = move\n",
        "        self.children = []\n",
        "        self.visits = 0\n",
        "        self.wins = 0\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"GameState: {self.game_state}, Move: {self.move}, Visits: {self.visits}, Wins: {self.wins}\"\n",
        "\n",
        "class MCTS:\n",
        "    def __init__(self, model, root):\n",
        "        self.model = model\n",
        "        self.root = root\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=0.001)\n",
        "        self.scheduler = torch.optim.lr_scheduler.StepLR(self.optimizer, step_size=100, gamma=0.1)\n",
        "\n",
        "    def choose_action(self, node):\n",
        "        # Check the mode of the model\n",
        "        if self.model.training:\n",
        "            # If the model is in training mode, use probabilistic action selection\n",
        "            visit_counts = np.array([child.visits for child in node.children])\n",
        "            visit_dist = visit_counts / visit_counts.sum()\n",
        "            chosen_action = node.children[np.random.choice(len(node.children), p=visit_dist)].move\n",
        "        else:\n",
        "            # If the model is in evaluation mode, use deterministic action selection\n",
        "            max_visits = max(child.visits for child in node.children)\n",
        "            chosen_action = [child.move for child in node.children if child.visits == max_visits][0]\n",
        "        return chosen_action\n",
        "\n",
        "    def selection(self, node):\n",
        "        while len(node.children) > 0:\n",
        "            max_value = -math.inf\n",
        "            selected_node = None\n",
        "            for child in node.children:\n",
        "                if child.visits == 0:  # Stop if the child node has not been visited yet\n",
        "                    return child\n",
        "                state_tensor = torch.tensor(child.game_state.to_array(), dtype=torch.float32)\n",
        "                policy, value = self.model(state_tensor)\n",
        "                Q = child.wins / child.visits if child.visits != 0 else 0\n",
        "                U = policy.mean() * math.sqrt(node.visits) / (1 + child.visits)\n",
        "                node_value = Q + U + child.policy.mean()  # Take the mean of the policy tensor\n",
        "                if node_value > max_value:\n",
        "                    max_value = node_value\n",
        "                    selected_node = child\n",
        "            node = selected_node\n",
        "        return node\n",
        "\n",
        "    def expansion(self, node):\n",
        "        # Get the list of legal moves from the game state\n",
        "        legal_moves = node.game_state.get_legal_moves()\n",
        "\n",
        "        # For each legal move, create a new node and add it to the children of the current node\n",
        "        for move in legal_moves:\n",
        "            new_game_state = node.game_state.make_move(move)\n",
        "            state_tensor = torch.tensor(new_game_state.to_array(), dtype=torch.float32)\n",
        "            policy, value = self.model(state_tensor)\n",
        "            child_node = Node(new_game_state, policy, parent=node, move=move)\n",
        "            node.children.append(child_node)\n",
        "\n",
        "        return node.children\n",
        "\n",
        "    def simulation(self, node):\n",
        "        game_state = node.game_state.copy()\n",
        "        while not game_state.is_terminal():\n",
        "            state_tensor = torch.tensor(game_state.to_array(), dtype=torch.float32)\n",
        "            policy, _ = self.model(state_tensor)\n",
        "            policy_dist = F.softmax(policy, dim=0).detach().numpy()\n",
        "            legal_moves = game_state.get_legal_moves()\n",
        "            move = np.random.choice(legal_moves, p=policy_dist)\n",
        "            game_state = game_state.make_move(move)\n",
        "            #print(f\"Game state after move: {game_state}\")  # Print the game state after each move\n",
        "        reward = game_state.get_reward()\n",
        "        #print(f\"Terminal game state reached with reward: {reward}\")  # Print the reward when a terminal state is reached\n",
        "        return reward\n",
        "\n",
        "    def backpropagation(self, node, reward):\n",
        "        # While node is not None\n",
        "        while node is not None:\n",
        "            # Update the visit count of the node\n",
        "            node.visits += 1\n",
        "\n",
        "            # Update the win count of the node\n",
        "            node.wins += reward\n",
        "\n",
        "            # Move to the parent node\n",
        "            node = node.parent\n",
        "\n",
        "    def print_tree(self, node, indent=\"\"):\n",
        "        print(indent + str(node))\n",
        "        for child in node.children:\n",
        "            self.print_tree(child, indent + \"  \")\n",
        "\n",
        "    # Train\n",
        "    def train(self, states, policies, rewards, epochs):\n",
        "        # Convert states, policies, and rewards to tensors\n",
        "        states = torch.tensor(states, dtype=torch.float32)\n",
        "        policies = torch.tensor(policies, dtype=torch.float32)\n",
        "        rewards = torch.tensor(rewards, dtype=torch.float32)\n",
        "\n",
        "        for _ in range(epochs):\n",
        "            policy_pred, value_pred = self.model(states)\n",
        "\n",
        "            policy_loss = F.kl_div(F.log_softmax(policy_pred, dim=1), policies)\n",
        "            value_loss = F.mse_loss(value_pred.squeeze(), rewards)\n",
        "            loss = policy_loss + value_loss\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "        return loss.item()\n",
        "\n",
        "    # Self Play\n",
        "    def self_play(self, network, game, game_number, num_simulations):\n",
        "        states = []\n",
        "        policies = []\n",
        "        current_state = game.get_initial_state()\n",
        "        root = Node(current_state, None)\n",
        "\n",
        "        for sim in range(num_simulations):\n",
        "            #print(f\"Starting simulation.\")\n",
        "            leaf = self.selection(root)\n",
        "            children = self.expansion(leaf)\n",
        "            self.simulation(random.choice(children))\n",
        "            legal_actions = game.get_legal_moves()\n",
        "            visit_counts = [child.visits if child.visits > 0 else torch.rand(1).item() for child in root.children]\n",
        "            policy = torch.zeros(network.policy_head.out_features)  # Initialize a zero vector of length equal to the output size of the policy head\n",
        "            for action, visit_count in zip(legal_actions, visit_counts):\n",
        "                policy[action - 1] = visit_count  # Subtract 1 from action to use it as an index\n",
        "            policy = F.softmax(policy, dim=0)\n",
        "\n",
        "            action_index = torch.multinomial(policy, 1).item()\n",
        "            action = root.children[action_index].move\n",
        "            states.append(prepare_data(current_state.to_array()))\n",
        "            policies.append(policy.tolist())  # Convert policy tensor to list\n",
        "            current_state = current_state.make_move(action + 1)  # Add 1 to action to use it as a move\n",
        "            root = root.children[action_index]\n",
        "\n",
        "        # Determine the reward based on the final state of the game\n",
        "        reward = current_state.get_reward()\n",
        "\n",
        "        return states, policies, reward  # Return policies as a list\n",
        "\n",
        "class MyReplayBuffer:\n",
        "    def __init__(self, max_size):\n",
        "        # Initialize your buffer with a maximum size\n",
        "        self.max_size = max_size\n",
        "        self.buffer = []\n",
        "\n",
        "    def add_transition(self, transition):\n",
        "        # Add a transition (state, action, reward, next_state) to the buffer\n",
        "        self.buffer.append(transition)\n",
        "        if len(self.buffer) > self.max_size:\n",
        "            self.buffer.pop(0)\n",
        "\n",
        "    def sample_batch(self, batch_size):\n",
        "        # Sample a batch of transitions\n",
        "        return random.sample(self.buffer, batch_size)\n",
        "\n",
        "class EloRating:\n",
        "    def __init__(self, initial_rating=1200, k=20):\n",
        "        self.rating = initial_rating\n",
        "        self.k = k\n",
        "\n",
        "    def update(self, score):\n",
        "        benchmark_rating = 10  # Set this to the desired benchmark performance level\n",
        "        expected_score = 1 / (1 + 10 ** ((benchmark_rating - self.rating) / 400))\n",
        "        self.rating += self.k * (score - expected_score)\n",
        "        return self.rating"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DtoYH_eB9lr"
      },
      "source": [
        "Initial Training Loop:\n",
        "\n",
        "A Replay Buffer helps to break the correlation between consecutive experiences, which is beneficial for the stability of the learning algorithm. The policy is represented implicitly by the actions chosen by the Monte Carlo Tree Search, which uses the neural network’s outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fc9tvyZeB6zh"
      },
      "outputs": [],
      "source": [
        "# Create the game and network\n",
        "game = GameState(0)  # Initialize the game\n",
        "num_actions = len(game.get_legal_moves())  # Get the number of possible actions\n",
        "network = PolicyValueResNet(num_actions)  # Initialize the policy-value network\n",
        "uniform_policy = [1.0 / num_actions] * num_actions  # Initialize a uniform policy\n",
        "root = Node(game.get_initial_state(), uniform_policy)  # Initialize the root node of the MCTS\n",
        "mcts = MCTS(network, root)  # Initialize the MCTS with the network and root node\n",
        "epoch_losses = []  # Initialize a list to store the losses per epoch\n",
        "elo_ratings = []\n",
        "\n",
        "# Initialize Elo rating\n",
        "elo = EloRating()\n",
        "\n",
        "network.train()  # Set the network to training mode\n",
        "\n",
        "game_number = 1  # Initialize the game number\n",
        "optimizer = torch.optim.Adam(network.parameters())  # Initialize the optimizer\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.1)  # Initialize the learning rate scheduler\n",
        "\n",
        "import random\n",
        "\n",
        "total_games = 0  # Initialize the total number of games played\n",
        "\n",
        "# Hyperparameters\n",
        "epochs = 100\n",
        "num_simulations = 20\n",
        "# Replay Buffer\n",
        "max_buffer_size = 1000\n",
        "replay_buffer = MyReplayBuffer(max_buffer_size)\n",
        "batch_size = 100\n",
        "subset_size = 80\n",
        "\n",
        "for i in range(epochs):\n",
        "    batch_states, batch_policies, batch_rewards = [], [], []\n",
        "    batch_losses = []\n",
        "\n",
        "    for j in range(batch_size):\n",
        "        # Collect transitions during self-play\n",
        "        states, policies, reward = mcts.self_play(network, game, game_number, num_simulations)\n",
        "        for state, policy, r in zip(states, policies, [reward] * len(states)):\n",
        "            replay_buffer.add_transition((state, policy, r))\n",
        "\n",
        "        total_games += 1\n",
        "        #print(f\"Game number {total_games} completed in batch {i + 1}\")\n",
        "\n",
        "    # Sample a subset from the buffer\n",
        "    batch_transitions = replay_buffer.sample_batch(subset_size)\n",
        "    subset_states, subset_policies, subset_rewards = zip(*batch_transitions)\n",
        "\n",
        "    # Train the network using the subset\n",
        "    loss = mcts.train(subset_states, subset_policies, subset_rewards, epochs)\n",
        "    batch_losses.append(loss)\n",
        "\n",
        "    avg_loss = sum(batch_losses) / len(batch_losses)\n",
        "    epoch_losses.append(avg_loss)\n",
        "    #print(f\"Average loss after epoch {i + 1}: {avg_loss}\")\n",
        "\n",
        "    # Adjust learning rate\n",
        "    scheduler.step()\n",
        "\n",
        "    # Update Elo rating based on the performance in this epoch\n",
        "    score = 1 if game.state == 10 else 0 if game.state > 10 else 0.5\n",
        "    elo.update(score)\n",
        "    elo_ratings.append(elo.rating)\n",
        "    #print(f\"Elo Rating after epoch {i + 1}: {elo.rating}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRFKPBfHv8ZN"
      },
      "source": [
        "Network:\n",
        "⌨\n",
        "\n",
        "Input is a 1D vector rather than a 2D Board or image. Adjust the network to use fully connected layers (nn.Linear) instead of 2D convolutional layers (nn.Conv2d). The idea behind a Residual Block is to introduce a so-called “skip connection” or “shortcut”, which allows the gradient to be directly backpropagated to earlier layers.\n",
        "\n",
        "During training, the network is updated to make its policy output match the actions selected by the Monte Carlo Tree Search (MCTS), and to make its value output match the final outcome of the simulated games."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "pru2HloYByJW"
      },
      "outputs": [],
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, num_channels):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(num_channels, num_channels)\n",
        "        self.fc2 = nn.Linear(num_channels, num_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.fc1(x))\n",
        "        out = self.fc2(out)\n",
        "        out += x  # Skip connection\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "class PolicyValueResNet(nn.Module):\n",
        "    def __init__(self, num_actions):\n",
        "        super().__init__()\n",
        "        self.hidden1 = nn.Linear(1, 64)\n",
        "        self.resblock = ResidualBlock(64)\n",
        "        self.hidden2 = nn.Linear(64, 64)\n",
        "\n",
        "        # Policy Head forms probabilities for each action, distribution\n",
        "        self.policy_head = nn.Linear(64, num_actions)\n",
        "\n",
        "        # Value Head predicts winner of game from each position, scaler\n",
        "        self.value_head = nn.Linear(64, 1)\n",
        "\n",
        "    def forward(self, state):\n",
        "        x = F.relu(self.hidden1(state))\n",
        "        x = self.resblock(x)\n",
        "        x = F.relu(self.hidden2(x))\n",
        "        policy = F.softmax(self.policy_head(x), dim=-1)\n",
        "        value = torch.tanh(self.value_head(x))\n",
        "        return policy, value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAF2Ys-ZCFdZ"
      },
      "source": [
        "Save - AddingGame_MCTS_Model2.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5h2irDtCI1h",
        "outputId": "08ecceed-bebd-41d6-ec42-1d464b7e317b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Save the model, optimizer, game number, average losses per epoch, total games, game state, and root node\n",
        "torch.save({\n",
        "    'model_state_dict': network.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'scheduler_state_dict': scheduler.state_dict(),\n",
        "    'game_number': game_number,\n",
        "    'epoch_losses': epoch_losses,\n",
        "    'total_games': total_games,\n",
        "    'game_state': game,\n",
        "    'root_node': root,\n",
        "    'elo_rating': elo.rating,\n",
        "    'elo_ratings': elo_ratings\n",
        "}, '/content/drive/My Drive/MCTS in Python/AddingGame_MCTS_Model2.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXPZBNPXCU7U"
      },
      "source": [
        "Load & Continue - AddingGame_MCTS_Model2.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nwmUGLMZCZqW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8741bdc5-22ce-47bb-b7bd-316d291c4126"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "game = GameState(0)  # Initialize the game\n",
        "num_actions = len(game.get_legal_moves())  # Get the number of possible actions\n",
        "network = PolicyValueResNet(num_actions)  # Initialize the policy-value network\n",
        "uniform_policy = [1.0 / num_actions] * num_actions  # Initialize a uniform policy\n",
        "root = Node(game.get_initial_state(), uniform_policy)  # Initialize the root node of the MCTS\n",
        "mcts = MCTS(network, root)  # Initialize the MCTS with the network and root node\n",
        "\n",
        "optimizer = torch.optim.Adam(network.parameters())  # Initialize the optimizer\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.1)  # Initialize the learning rate scheduler\n",
        "\n",
        "# Load the saved model, optimizer, scheduler, and other necessary variables from the checkpoint\n",
        "checkpoint = torch.load('/content/drive/My Drive/MCTS in Python/AddingGame_MCTS_Model2.pth')\n",
        "network.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "game_number = checkpoint['game_number']\n",
        "epoch_losses = checkpoint['epoch_losses']\n",
        "total_games = checkpoint['total_games']\n",
        "game = checkpoint['game_state']\n",
        "root = checkpoint['root_node']\n",
        "elo_rating = checkpoint['elo_rating']\n",
        "elo_ratings = checkpoint['elo_ratings']\n",
        "\n",
        "elo = EloRating(initial_rating=elo_rating)\n",
        "\n",
        "# Continue training\n",
        "network.train()  # Ensure the network is in training mode\n",
        "epochs = 500\n",
        "num_simulations = 50\n",
        "max_buffer_size = 1000\n",
        "replay_buffer = MyReplayBuffer(max_buffer_size)  # Initialize the replay buffer\n",
        "batch_size = 100\n",
        "subset_size = 80\n",
        "\n",
        "for i in range(epochs):\n",
        "    batch_states, batch_policies, batch_rewards = [], [], []\n",
        "    batch_losses = []\n",
        "    for j in range(batch_size):\n",
        "        # Perform self-play and add the resulting states, policies, and rewards to the batch\n",
        "        states, policies, reward = mcts.self_play(network, game, game_number, num_simulations)\n",
        "        for state, policy, r in zip(states, policies, [reward] * len(states)):\n",
        "            replay_buffer.add_transition((state, policy, r))  # Add transitions to the replay buffer\n",
        "        total_games += 1\n",
        "        #print(f\"Game number {total_games} completed in batch {i + 1}\")\n",
        "    # Sample a random subset of transitions from the replay buffer\n",
        "    batch_transitions = replay_buffer.sample_batch(subset_size)\n",
        "    subset_states, subset_policies, subset_rewards = zip(*batch_transitions)\n",
        "    # Train the network on the subset and calculate the loss\n",
        "    loss = mcts.train(subset_states, subset_policies, subset_rewards, epochs)\n",
        "    batch_losses.append(loss)\n",
        "    avg_loss = sum(batch_losses) / len(batch_losses)\n",
        "    epoch_losses.append(avg_loss)\n",
        "    #print(f\"Average loss after epoch {i + 1}: {avg_loss}\")\n",
        "    scheduler.step()  # Update the learning rate\n",
        "\n",
        "    # Update Elo rating based on the performance in this epoch\n",
        "    score = 1 if game.state == 10 else 0 if game.state > 10 else 0.5\n",
        "    elo.update(score)\n",
        "    elo_ratings.append(elo.rating)\n",
        "    #print(f\"Elo Rating after epoch {i + 1}: {elo.rating}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgQNH257CsqR"
      },
      "source": [
        "Plots for Loss and Elo Rating:\n",
        "\n",
        "The Elo rating system is a tool to measure performance and guide learning. A decreasing Elo rating could mean that the model is exploring the game space and making necessary mistakes to learn. Over time, as the model learns from these mistakes, its performance and Elo rating should start to improve. If the Elo rating continues to decrease over a long period of time, it might be worth revisiting your training process, learning rate, or the design of your model. It could be that the model is stuck in a suboptimal strategy, or that the learning rate is too high or too low."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UPoohsmUCrX4"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a figure and a set of subplots\n",
        "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(8, 4))\n",
        "\n",
        "# Plot the average losses per epoch\n",
        "axs[0].plot(range(1, len(epoch_losses) + 1), epoch_losses)  # Use epoch numbers as x-axis\n",
        "axs[0].set_xlabel('Epoch')\n",
        "axs[0].set_ylabel('Average Loss')\n",
        "axs[0].set_title('Average Loss per Epoch')\n",
        "\n",
        "# Plot the Elo ratings per epoch\n",
        "# Assuming elo_ratings is a list of Elo ratings after each epoch\n",
        "axs[1].plot(range(1, len(elo_ratings) + 1), elo_ratings)  # Use epoch numbers as x-axis\n",
        "axs[1].set_xlabel('Epoch')\n",
        "axs[1].set_ylabel('Elo Rating')\n",
        "axs[1].set_title('Elo Rating per Epoch')\n",
        "\n",
        "# Display the plots\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjoxJ-3iCvEf"
      },
      "source": [
        "Play, Eval() - AddingGame_MCTS_Model2.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "MwqfjyLTCyTP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d61c4dc8-fd9b-489a-81c8-0c91a7cf28d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Win rate: 0.14\n"
          ]
        }
      ],
      "source": [
        "# Initialize a list to store the results of each game\n",
        "rewards = []\n",
        "elo = EloRating()\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "game = GameState(0)\n",
        "num_actions = len(game.get_legal_moves())\n",
        "network = PolicyValueResNet(num_actions)\n",
        "uniform_policy = [1.0 / num_actions] * num_actions\n",
        "root = Node(game.get_initial_state(), uniform_policy)\n",
        "mcts = MCTS(network, root)\n",
        "\n",
        "# Load the model and optimizer\n",
        "checkpoint = torch.load('/content/drive/My Drive/MCTS in Python/AddingGame_MCTS_Model2.pth')\n",
        "network.load_state_dict(checkpoint['model_state_dict'])\n",
        "mcts.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "network.eval()\n",
        "\n",
        "num_games = 100\n",
        "num_sims = 50\n",
        "elo_ratings = []  # Initialize a list to store the Elo ratings\n",
        "\n",
        "for i in range(num_games):\n",
        "    #print(f\"Game {i + 1}:\")\n",
        "\n",
        "    # Initialize the game and the root node\n",
        "    game_state = game.get_initial_state()\n",
        "    root = Node(game_state, None)\n",
        "\n",
        "    # Make sure that the MCTS and the root node persist throughout each game\n",
        "    mcts = MCTS(network, root)\n",
        "\n",
        "    while not game_state.is_terminal():\n",
        "        # Perform MCTS simulations from the root\n",
        "        for _ in range(num_sims):\n",
        "            leaf = mcts.selection(root)\n",
        "            children = mcts.expansion(leaf)\n",
        "            reward = mcts.simulation(random.choice(children))\n",
        "            mcts.backpropagation(leaf, reward)\n",
        "\n",
        "        # Choose the action that leads to the most visited child node\n",
        "        action = mcts.choose_action(root)\n",
        "\n",
        "        # Apply the action to get the next state\n",
        "        game_state = game_state.make_move(action)\n",
        "\n",
        "        #print(f\"Action taken: {action}\")\n",
        "\n",
        "    #print(f\"Final reward: {reward}\")\n",
        "\n",
        "    # Append the result of the game to the rewards list\n",
        "    rewards.append(reward)\n",
        "\n",
        "    # Update Elo rating based on the performance in this game\n",
        "    score = 1 if reward == 1 else 0 if reward == -1 else 0.5\n",
        "    elo.update(score)\n",
        "    elo_ratings.append(elo.rating)  # Append the updated Elo rating to the list\n",
        "\n",
        "    #print(f\"Elo rating after game {i + 1}: {elo.rating}\")\n",
        "\n",
        "# Calculate the win rate\n",
        "win_rate = rewards.count(1) / num_games\n",
        "\n",
        "print(f\"Win rate: {win_rate}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot Elo rating over time\n",
        "plt.plot(range(1, num_games + 1), elo_ratings)\n",
        "plt.xlabel('Game number')\n",
        "plt.ylabel('Elo rating')\n",
        "plt.title('Elo rating over time')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BbbVywLxcSah",
        "outputId": "5259858b-a445-45ad-c388-1577a0941ebf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkQAAAHHCAYAAABeLEexAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABhfUlEQVR4nO3dd1hTZ8MG8PskIWEGBAREUXGDW1DEWd9St3XWarHitoq2Vu1bbetqq1Q73latqw6sW1u1jtrWOqsiIO4BLlRQGYoQZoDkfH9Y8zV1gQZOIPfvunJ9zTlPkjvnezW3ZzxHEEVRBBEREZEFk0kdgIiIiEhqLERERERk8ViIiIiIyOKxEBEREZHFYyEiIiIii8dCRERERBaPhYiIiIgsHgsRERERWTwWIiIiIrJ4LEREFkQQBMycOVPqGEUyc+ZMCIIgdYwy65VXXsErr7widQyiMoOFiKiMCw8PhyAIT30cP35c6ohPlZOTg5kzZ+LgwYNSRymTLl68iJkzZ+LGjRtSRyEq8xRSByAi0/j000/h7e392PJatWpJkKZocnJyMGvWLAB4bG/GJ598gilTpkiQquy4ePEiZs2ahVdeeQXVq1c3WvfHH39IE4qojGIhIionunTpAn9/f0kzFBYWQq/XQ6lUvvR7KRQKKBT8Kyo7Oxt2dnbFfp0p/n9AZEl4yIzIwp06dQpdunSBWq2Gvb09Xn311SIdZrtx4wYEQcBXX32Fb7/9FjVr1oRKpcLFixeRn5+P6dOnw8/PD46OjrCzs0Pbtm1x4MABo9dXrFgRADBr1izDIb5H5zg96RwiQRAwbtw4bN++HQ0aNIBKpUL9+vXx22+/PZbv4MGD8Pf3h7W1NWrWrImlS5cW67ykLVu2wM/PDzY2NnB1dcWgQYNw+/Ztw/qvvvoKgiDg5s2bj7126tSpUCqVePDggWFZZGQkOnfuDEdHR9ja2qJ9+/Y4evSo0ese5bt48SLeeustVKhQAW3atHlivvDwcLzxxhsAgA4dOhi236PDj/8+h+jgwYMQBAGbN2/GrFmzULlyZTg4OKBfv37IyMiAVqvFhAkT4ObmBnt7ewwdOhRarfaxz127dq1huzg7O2PAgAFISEgo0jYlMmf85xdROZGRkYF79+4ZLRMEAS4uLk99zYULF9C2bVuo1Wr897//hZWVFZYuXYpXXnkFhw4dQkBAwHM/d9WqVcjLy8OoUaOgUqng7OwMjUaD5cuXY+DAgRg5ciQyMzOxYsUKdOrUCVFRUWjSpAkqVqyIxYsXY8yYMejduzf69OkDAGjUqNEzP+/IkSPYunUrxo4dCwcHB8yfPx99+/bFrVu3DN/11KlT6Ny5MypVqoRZs2ZBp9Ph008/NRSw5wkPD8fQoUPRvHlzhIWFITk5Gd999x2OHj2KU6dOwcnJCf3798d///tfbN68GR988IHR6zdv3oyOHTuiQoUKAID9+/ejS5cu8PPzw4wZMyCTybBq1Sr85z//wV9//YUWLVoYvf6NN95A7dq1MWfOHIii+MSM7dq1w7vvvov58+fjo48+go+PDwAY/u/ThIWFwcbGBlOmTMHVq1exYMECWFlZQSaT4cGDB5g5cyaOHz+O8PBweHt7Y/r06YbXzp49G9OmTUP//v0xYsQIpKamYsGCBWjXrp1huxCVWSIRlWmrVq0SATzxoVKpjMYCEGfMmGF43qtXL1GpVIrXrl0zLLtz547o4OAgtmvX7pmfGx8fLwIQ1Wq1mJKSYrSusLBQ1Gq1RssePHgguru7i8OGDTMsS01NfSzTIzNmzBD//VcUAFGpVIpXr141LDtz5owIQFywYIFhWY8ePURbW1vx9u3bhmVXrlwRFQrFY+/5b/n5+aKbm5vYoEEDMTc317B8165dIgBx+vTphmWBgYGin5+f0eujoqJEAOKPP/4oiqIo6vV6sXbt2mKnTp1EvV5vGJeTkyN6e3uLr7322mPfeeDAgc/M+MiWLVtEAOKBAwceW9e+fXuxffv2hucHDhwQAYgNGjQQ8/PzDcsHDhwoCoIgdunSxej1gYGBYrVq1QzPb9y4IcrlcnH27NlG486dOycqFIrHlhOVNTxkRlROfP/999i7d6/RY8+ePU8dr9Pp8Mcff6BXr16oUaOGYXmlSpXw1ltv4ciRI9BoNM/93L59+z6250UulxvOYdHr9UhLS0NhYSH8/f1x8uTJF/yGDwUFBaFmzZqG540aNYJarcb169cN3+vPP/9Er1694OnpaRhXq1YtdOnS5bnvf+LECaSkpGDs2LGwtrY2LO/WrRvq1auH3bt3G5a9+eabiImJwbVr1wzLNm3aBJVKhZ49ewIATp8+jStXruCtt97C/fv3ce/ePdy7dw/Z2dl49dVXcfjwYej1eqMM77zzTjG3StENHjwYVlZWhucBAQEQRRHDhg0zGhcQEICEhAQUFhYCALZu3Qq9Xo/+/fsbvsO9e/fg4eGB2rVrGx0OJSqLeMiMqJxo0aJFsU6qTk1NRU5ODurWrfvYOh8fH+j1eiQkJKB+/frPfJ8nXdkGAKtXr8bXX3+N2NhYFBQUPHd8UVWtWvWxZRUqVDCcr5OSkoLc3NwnXl1XlCvuHp0T9KTtUq9ePRw5csTw/I033sDEiROxadMmfPTRRxBFEVu2bDGckwUAV65cAQCEhIQ89TMzMjIMh9eAl99Gz/Lv7efo6AgA8PLyemy5Xq9HRkYGXFxccOXKFYiiiNq1az/xff9ZsojKIhYiInopNjY2jy1bu3YthgwZgl69euGDDz6Am5sb5HI5wsLCjPamvAi5XP7E5eJTzrUpSZ6enmjbti02b96Mjz76CMePH8etW7cwd+5cw5hHe3++/PJLNGnS5InvY29vb/T8SdvUVJ62/Z63XfV6PQRBwJ49e5449t/fgaisYSEislAVK1aEra0t4uLiHlsXGxsLmUz22F6Dovrpp59Qo0YNbN261eiqrhkzZhiNK4mZqN3c3GBtbY2rV68+tu5Jy/6tWrVqAIC4uDj85z//MVoXFxdnWP/Im2++ibFjxyIuLg6bNm2Cra0tevToYVj/6PCeWq1GUFBQsb/Ps5TmTN41a9aEKIrw9vZGnTp1Su1ziUoLzyEislByuRwdO3bEL7/8YjTTcXJyMtavX482bdoYDvu8yHsDxnttIiMjERERYTTO1tYWAJCenv5Cn/O0zw4KCsL27dtx584dw/KrV68+85yqR/z9/eHm5oYlS5YYXXa+Z88eXLp0Cd26dTMa37dvX8jlcmzYsAFbtmxB9+7djeYN8vPzQ82aNfHVV18hKyvrsc9LTU19ka8JAIbPMeX2e5o+ffpALpdj1qxZj+2NE0UR9+/fL/EMRCWJe4iIyok9e/YgNjb2seWtWrUyOmn6nz7//HPs3bsXbdq0wdixY6FQKLB06VJotVrMmzfvhbN0794dW7duRe/evdGtWzfEx8djyZIl8PX1NSoFNjY28PX1xaZNm1CnTh04OzujQYMGaNCgwQt/NvBwPp8//vgDrVu3xpgxY6DT6bBw4UI0aNAAp0+ffuZrraysMHfuXAwdOhTt27fHwIEDDZfdV69eHe+//77ReDc3N3To0AHffPMNMjMz8eabbxqtl8lkWL58Obp06YL69etj6NChqFy5Mm7fvo0DBw5ArVZj586dL/Q9mzRpArlcjrlz5yIjIwMqlQr/+c9/4Obm9kLv9yw1a9bE559/jqlTp+LGjRvo1asXHBwcEB8fj23btmHUqFGYPHmyyT+XqNRIdn0bEZnEsy67ByCuWrXKMBZPuMT95MmTYqdOnUR7e3vR1tZW7NChg3js2LHnfu6jy+6//PLLx9bp9Xpxzpw5YrVq1USVSiU2bdpU3LVrlxgSEmJ0KbcoiuKxY8dEPz8/UalUGuV72mX3oaGhj31etWrVxJCQEKNl+/btE5s2bSoqlUqxZs2a4vLly8VJkyaJ1tbWz/1uoiiKmzZtEps2bSqqVCrR2dlZDA4OFhMTE5849ocffhABiA4ODkaX6v/TqVOnxD59+oguLi6iSqUSq1WrJvbv31/ct2+fYcyj75yamlqkjI8+u0aNGqJcLje6BP9pl91v2bLF6PWP/vcTHR1ttPxpWX7++WexTZs2op2dnWhnZyfWq1dPDA0NFePi4oqcmcgcCaIowZmIREQS6NWrFy5cuGC48ouI6BGeQ0RE5VJubq7R8ytXruDXX3997CayREQAwD1ERFQuVapUCUOGDEGNGjVw8+ZNLF68GFqtFqdOnXrqXDpEZLl4UjURlUudO3fGhg0bkJSUBJVKhcDAQMyZM4dliIieiHuIiIiIyOLxHCIiIiKyeCxEREREZPF4DlER6PV63LlzBw4ODqU6VT4RERG9OFEUkZmZCU9PT8hkz94HxEJUBHfu3HnhezoRERGRtBISElClSpVnjmEhKgIHBwcADzfoi97biYiIiEqXRqOBl5eX4Xf8WViIiuDRYTK1Ws1CREREVMYU5XQXnlRNREREFo+FiIiIiCweCxERERFZPBYiIiIisniSFqLDhw+jR48e8PT0hCAI2L59u2FdQUEBPvzwQzRs2BB2dnbw9PTE4MGDcefOHaP3SEtLQ3BwMNRqNZycnDB8+HBkZWUZjTl79izatm0La2treHl5Yd68eaXx9YiIiKiMkLQQZWdno3Hjxvj+++8fW5eTk4OTJ09i2rRpOHnyJLZu3Yq4uDi8/vrrRuOCg4Nx4cIF7N27F7t27cLhw4cxatQow3qNRoOOHTuiWrVqiImJwZdffomZM2di2bJlJf79iIiIqGwwm5u7CoKAbdu2oVevXk8dEx0djRYtWuDmzZuoWrUqLl26BF9fX0RHR8Pf3x8A8Ntvv6Fr165ITEyEp6cnFi9ejI8//hhJSUlQKpUAgClTpmD79u2IjY0tUjaNRgNHR0dkZGTwsnsiIqIyoji/32XqHKKMjAwIggAnJycAQEREBJycnAxlCACCgoIgk8kQGRlpGNOuXTtDGQKATp06IS4uDg8ePCjV/ERERGSeyszEjHl5efjwww8xcOBAQ8tLSkqCm5ub0TiFQgFnZ2ckJSUZxnh7exuNcXd3N6yrUKHCY5+l1Wqh1WoNzzUajUm/CxEREZmXMrGHqKCgAP3794coili8eHGJf15YWBgcHR0ND97HjIiIqHwz+0L0qAzdvHkTe/fuNToG6OHhgZSUFKPxhYWFSEtLg4eHh2FMcnKy0ZhHzx+N+bepU6ciIyPD8EhISDDlVyIiIiIzY9aF6FEZunLlCv7880+4uLgYrQ8MDER6ejpiYmIMy/bv3w+9Xo+AgADDmMOHD6OgoMAwZu/evahbt+4TD5cBgEqlMty3jPcvIyIiKv8kLURZWVk4ffo0Tp8+DQCIj4/H6dOncevWLRQUFKBfv344ceIE1q1bB51Oh6SkJCQlJSE/Px8A4OPjg86dO2PkyJGIiorC0aNHMW7cOAwYMACenp4AgLfeegtKpRLDhw/HhQsXsGnTJnz33XeYOHGiVF/byPXULFxNyXr+QCIiIioxkl52f/DgQXTo0OGx5SEhIZg5c+ZjJ0M/cuDAAbzyyisAHk7MOG7cOOzcuRMymQx9+/bF/PnzYW9vbxh/9uxZhIaGIjo6Gq6urhg/fjw+/PDDIucsqcvuzyamY/DKKNirFNg2tjUqOqhM9t5ERESWrji/32YzD5E5K6lCdD9Liz6Lj+Hm/Rw0quKIjaNawlZZZi78IyIiMmvldh6i8sbFXoXwoS1QwdYKZxMz8O6GU9Dp2U+JiIhKGwuRxLxd7bA8pDlUChn+vJSCmTsugDvtiIiIShcLkRnwq1YB377ZBIIArDl+Ez/8dV3qSERERBaFhchMdGlYCR939QEAzPk1FrvO3pE4ERERkeVgITIjw9t4Y0ir6gCAiZvP4MSNNGkDERERWQgWIjMiCAKmdfdFR1935BfqMeLHE7ieyjmKiIiIShoLkZmRywR8N6ApGns5IT2nAENWReNelvb5LyQiIqIXxkJkhmyUcqwI8UdVZ1vcSsvB8NUnkJuvkzoWERFRucVCZKZc7VVYNbQ5nGytcCYhHe9t5BxFREREJYWFyIzVrGiPHwb7Q6mQ4Y+Lyfhs10WpIxEREZVLLERmrnl1Z3zTvzEAIPzYDaw4Ei9xIiIiovKHhagM6N7IE1O71AMAfL77IvacuytxIiIiovKFhaiMGNWuBga1rApRBCZsOo2Ymw+kjkRERFRusBCVEYIgYGaP+ni1nhu0hXqM/PEEbtzLljoWERFRucBCVIYo5DIseKspGlZ2RFp2PoasikJadr7UsYiIiMo8FqIyxlapwIoh/qjsZIMb93MwYnU08go4RxEREdHLYCEqg9wcrLF6WHOorRU4eSsd7286DT3nKCIiInphLERlVC03Bywb7A+lXIY955Mw59dLUkciIiIqs1iIyrCWNVzw5RuNAADLj8Qj/CjnKCIiInoRLERlXM8mlfFBp7oAgFm7LuL3C0kSJyIiIip7WIjKgbGv1MTAFg/nKHpv4ymcTkiXOhIREVGZwkJUDgiCgM961scrdSsir0CP4eHRuHU/R+pYREREZQYLUTmhkMuw8K1mqO+pxv2/5yh6wDmKiIiIioSFqByxVymwckhzeDpa4/q9bIxac4JzFBERERUBC1E54662RviwFnCwViD6xgNM2nKGcxQRERE9BwtROVTH3QFLB/nBSi5g99m7mPt7rNSRiIiIzBoLUTnVqpYr5vZ9OEfR0kPXseb4TYkTERERmS8WonKsT7MqmPRaHQDAjF/OY9+lZIkTERERmScWonJu3H9q4U1/L+hFYNz6UzibmC51JCIiIrPDQlTOCYKAz3s3QNvarsgt0GFY+AkkpHGOIiIion9iIbIAVnIZFgU3g08lNe5laTE0PBoZOQVSxyIiIjIbLEQWwsHaCquGNEclR2tcTcnCqDUnoC3kHEVEREQAC5FF8XC0xqqhzeGgUiAyPg0fbDnLOYqIiIjAQmRx6nmosXiQHxQyATvO3MFXf8RJHYmIiEhyLEQWqE1tV3zx9xxFiw5ew7pIzlFERESWjYXIQvXzq4IJQbUBANN/uYADsSkSJyIiIpIOC5EFe+/V2ujnVwU6vYjQ9Sdx/naG1JGIiIgkwUJkwQRBQFifhmhb2xU5+ToMDY9G4gPOUURERJaHhcjCPZqjqJ6HA1IztRi6KhoZuZyjiIiILAsLET2co2hoc3iorXElJQujOUcRERFZGBYiAgBUcrTByiHNYa9S4Pj1NHz401mIIucoIiIiy8BCRAa+nmosHtQMCpmA7afv4Os/LksdiYiIqFRIWogOHz6MHj16wNPTE4IgYPv27UbrRVHE9OnTUalSJdjY2CAoKAhXrlwxGpOWlobg4GCo1Wo4OTlh+PDhyMrKMhpz9uxZtG3bFtbW1vDy8sK8efNK+quVWW1rV8ScPg0BAAsPXMWGqFsSJyIiIip5khai7OxsNG7cGN9///0T18+bNw/z58/HkiVLEBkZCTs7O3Tq1Al5eXmGMcHBwbhw4QL27t2LXbt24fDhwxg1apRhvUajQceOHVGtWjXExMTgyy+/xMyZM7Fs2bIS/35lVX9/L7z76sM5ij7Zfh4H4jhHERERlW+CaCYnigiCgG3btqFXr14AHu4d8vT0xKRJkzB58mQAQEZGBtzd3REeHo4BAwbg0qVL8PX1RXR0NPz9/QEAv/32G7p27YrExER4enpi8eLF+Pjjj5GUlASlUgkAmDJlCrZv347Y2NgiZdNoNHB0dERGRgbUarXpv7wZEkURk7acwdaTt2GrlGPhW01R0d4aIkSIImBvrUDNivZSxyQiInqq4vx+K0opU7HFx8cjKSkJQUFBhmWOjo4ICAhAREQEBgwYgIiICDg5ORnKEAAEBQVBJpMhMjISvXv3RkREBNq1a2coQwDQqVMnzJ07Fw8ePECFChUe+2ytVgutVmt4rtFoSuhbmi9BEPBFn0ZI1uTh6NX7GBZ+4rExQ1pVx4wevhAEQYKEREREpmO2J1UnJSUBANzd3Y2Wu7u7G9YlJSXBzc3NaL1CoYCzs7PRmCe9xz8/49/CwsLg6OhoeHh5eb38FyqDlAoZFg/yw2u+7vBQW6OSozU8/34IAhB+7AaWHb4udUwiIqKXZrZ7iKQ0depUTJw40fBco9FYbClSW1vhh8H+jy1feSQen+66iLA9sfB0skGPxp4SpCMiIjINs91D5OHhAQBITk42Wp6cnGxY5+HhgZQU4xN+CwsLkZaWZjTmSe/xz8/4N5VKBbVabfQgY8PaeGNYa28AwKTNZxAVnyZxIiIiohdntoXI29sbHh4e2Ldvn2GZRqNBZGQkAgMDAQCBgYFIT09HTEyMYcz+/fuh1+sREBBgGHP48GEUFPz/7Sj27t2LunXrPvH8ISq6j7v5oHN9D+Tr9Bj54wlcTcl6/ouIiIjMkKSFKCsrC6dPn8bp06cBPDyR+vTp07h16xYEQcCECRPw+eefY8eOHTh37hwGDx4MT09Pw5VoPj4+6Ny5M0aOHImoqCgcPXoU48aNw4ABA+Dp+fAQzltvvQWlUonhw4fjwoUL2LRpE7777jujQ2L0YuQyAd8OaIKmVZ2QkVuAIauikJqpff4LiYiIzIykl90fPHgQHTp0eGx5SEgIwsPDIYoiZsyYgWXLliE9PR1t2rTBokWLUKdOHcPYtLQ0jBs3Djt37oRMJkPfvn0xf/582Nv//yXhZ8+eRWhoKKKjo+Hq6orx48fjww8/LHJOS7zsvjjuZ2nRd/Ex3Lifg0ZVHLFxVEvYKnl6GhERSas4v99mMw+ROWMher4b97LRZ/ExpGXn49V6blj6th8UcrM9IktERBagOL/f/MUik6juaocfBvtDpZBhX2wKZu68wJvDEhFRmcFCRCbjV60CvhvQBIIArD1+i3MUERFRmcFCRCbVuUElfNLNFwAQticWO8/ckTgRERHR87EQkckNb+ONoa2rA+AcRUREVDawEFGJ+KSbLzrVd+ccRUREVCawEFGJkMsEfDegKecoIiKiMoGFiEqMtZUcywf7o7qLLRIf5GL46mjk5BdKHYuIiOgxLERUolzsVQgf2gLOdkqcTczA+PWnUKjTSx2LiIjICAsRlTjOUUREROaOhYhKxb/nKFrKOYqIiMiMsBBRqencoBKm/T1H0Rd7YrGDcxQREZGZYCGiUjWsjTeGtfYGAEzefAaR1+9LnIiIiIiFiCTwSTcfdGng8Y85ijKljkRERBaOhYhKnUwm4H9vNkGzqk7Q5BUiZGU0UjLzpI5FREQWjIWIJGFtJcfykObwdrXD7fRcDAuPRraWcxQREZE0WIhIMs52Sqwa0hzOdkqcv63BuPUnOUcRERFJgoWIJFXd1Q4rQvxhbSXDgbhUTPuFcxQREVHpU0gdgKhp1Qr4bkBTvLM2BhuibsHVXokgH3foRRGPqlEDT0coFezvRERUMgSR/xx/Lo1GA0dHR2RkZECtVksdp9wKPxqPmTsvPnFdjYp2+OmdVnC2U5ZyKiIiKquK8/vNf3KT2RjS2htTutSDl7MNKjvZoEoFG1R1toW9SoHrqdkYsToaeQU6qWMSEVE5xD1ERcA9RNK6mpKJvosjkJFbgM71PfB9cDPIZYLUsYiIyMxxDxGVK7XcHLDsbT8o5TL8diEJs3dfkjoSERGVMyxEVCYE1HDBV/0bAwBWHo3HiiPxEiciIqLyhIWIyozXG3tiapd6AIDPd1/EnnN3JU5ERETlBQsRlSmj2tXA4MBqEEVgwqbTiLmZJnUkIiIqB1iIqEwRBAEzetRHkI87tIV6jFh9AtdTs6SORUREZRwLEZU5cpmABQOborGXEx7kFGDIqmjcy9JKHYuIiMowFiIqk2yUcqwI8UdVZ1vcSsvB8PBo5OTz5rBERPRiWIiozHK1VyF8aHM42VrhTGIG3t1wCjo9p9UiIqLiYyGiMq1GRXusCPGHUiHDn5dSMHMHbw5LRETFx0JEZZ5fNWd892YTCAKw5vhNLD18XepIRERUxrAQUbnQpWElfNLNFwDwxZ5Y/HL6tsSJiIioLGEhonJjeBtvDGvtDQD4YMtZHL9+X+JERERUVrAQUbnycTcfdK7vgXydHqN+PIEryZlSRyIiojKAhYjKFblMwLcDmsCvWgVo8goxZFU0UjR5UsciIiIzx0JE5Y61lRw/DPaHt6sdbqfnYmh4NLK0nKOIiIiejoWIyiVnOyXChzaHi50SF+5oELruJAp0eqljERGRmWIhonKrmosdVgxpDmsrGQ5dTsXH285xjiIiInoiFiIq15p4OWHhwGaQCcDmE4mYv++q1JGIiMgMsRBRuRfk645ZPRsAAP7352VsOZEgcSIiIjI3LERkEd5uWQ3vtK8JAJi69RwOX06VOBEREZkTsy5EOp0O06ZNg7e3N2xsbFCzZk189tlnRueBiKKI6dOno1KlSrCxsUFQUBCuXLli9D5paWkIDg6GWq2Gk5MThg8fjqysrNL+OiSx/3aqi55NPFGoFzF23UlcuJMhdSQiIjITZl2I5s6di8WLF2PhwoW4dOkS5s6di3nz5mHBggWGMfPmzcP8+fOxZMkSREZGws7ODp06dUJe3v/PPRMcHIwLFy5g79692LVrFw4fPoxRo0ZJ8ZVIQjKZgHn9GqFlDWdkaQsxdFU0bqfnSh2LiIjMgCCa8WU33bt3h7u7O1asWGFY1rdvX9jY2GDt2rUQRRGenp6YNGkSJk+eDADIyMiAu7s7wsPDMWDAAFy6dAm+vr6Ijo6Gv78/AOC3335D165dkZiYCE9Pz+fm0Gg0cHR0REZGBtRqdcl8WSo1GbkFeGPJMVxOzkIdd3tseacVHG2spI5FREQmVpzfb7PeQ9SqVSvs27cPly9fBgCcOXMGR44cQZcuXQAA8fHxSEpKQlBQkOE1jo6OCAgIQEREBAAgIiICTk5OhjIEAEFBQZDJZIiMjHzi52q1Wmg0GqMHlR+ONlZYNbQF3NUqXE7OwqgfT0BbqJM6FhERScisC9GUKVMwYMAA1KtXD1ZWVmjatCkmTJiA4OBgAEBSUhIAwN3d3eh17u7uhnVJSUlwc3MzWq9QKODs7GwY829hYWFwdHQ0PLy8vEz91UhilZ1ssHJIc9irFIiMT8MHW85CrzfbnaVERFTCzLoQbd68GevWrcP69etx8uRJrF69Gl999RVWr15dop87depUZGRkGB4JCbxMuzyq7+mIRcHNoJAJ2HHmDub9Hid1JCIikohZF6IPPvjAsJeoYcOGePvtt/H+++8jLCwMAODh4QEASE5ONnpdcnKyYZ2HhwdSUlKM1hcWFiItLc0w5t9UKhXUarXRg8qndnUq4ou+jQAASw5dw48RN6QNREREkjDrQpSTkwOZzDiiXC6HXv/wnlTe3t7w8PDAvn37DOs1Gg0iIyMRGBgIAAgMDER6ejpiYmIMY/bv3w+9Xo+AgIBS+BZk7vr5VcHE1+oAAGbuuIC9F5Of8woiIipvzLoQ9ejRA7Nnz8bu3btx48YNbNu2Dd988w169+4NABAEARMmTMDnn3+OHTt24Ny5cxg8eDA8PT3Rq1cvAICPjw86d+6MkSNHIioqCkePHsW4ceMwYMCAIl1hRpZh/H9qYUBzL+hFYPyGkzh164HUkYiIqBSZ9WX3mZmZmDZtGrZt24aUlBR4enpi4MCBmD59OpRKJYCHEzPOmDEDy5YtQ3p6Otq0aYNFixahTp06hvdJS0vDuHHjsHPnTshkMvTt2xfz58+Hvb19kXLwsnvLUKjTY+SPJ3AgLhXOdkpsHdMK1V3tpI5FREQvqDi/32ZdiMwFC5HlyNYWYsCy4zh3OwPVXGyxdUwruNirpI5FREQvoNzMQ0RU2uxUCqwc0hxezja4eT8Hw1afQG4+5ygiIirvWIiI/qWigwrhQ1vAydYKZxLSMX7DKeg4RxERUbnGQkT0BDUr2mP5YH8oFTL8eSkZM3acB48uExGVXyxERE/hX90Z8wc0gSAAa4/fwpJD16WOREREJYSFiOgZOjeohOndfQEAc3+LxfZTtyVOREREJYGFiOg5hrb2xsi23gCAD346g6NX70mciIiITI2FiKgIpnbxQbdGlVCgE/HOmhhcuquROhIREZmQQuoARGWBTCbg6zcaIzVTi6j4NPRfGgEPtTV0ehGFehF6UUTPJp6Y3LEuBEGQOi4RERUT9xARFZG1lRw/vO2POu72yMwrxJWULFy/l41baTlIfJCL7w9cw//+vCJ1TCIiegHcQ0RUDI62Vtg5vg1ibjwABEAhk0EhFxBz4wFm/3oJ8/ddQSVHawxsUVXqqEREVAwsRETFpFLI0aqWq9GyZlUrIDOvAPP3X8Un28/DXa3Cf+q5S5SQiIiKi4fMiEzk/dfqoJ9fFej0IkLXncKZhHSpIxERURGxEBGZiCAICOvTEO3qVERugQ7DwqNx83621LGIiKgIWIiITMhKLsOi4GZoUFmN+9n5GLIqGveztFLHIiKi52AhIjIxe5UCK0Oao7KTDeLvZWP46hPIzddJHYuIiJ6BhYioBLiprbF6WAs42VrhdEI6xm84hUKdXupYRET0FCxERCWklps9lg/2h0ohw5+XkjFjxwWIoih1LCIiegIWIqIS5F/dGd8NaApBANZF3sKig9ekjkRERE/AQkRUwjo38MDMHvUBAF/+HoefYxIlTkRERP/GQkRUCkJaVcfo9jUAAB/+fBaHL6dKnIiIiP6JhYiolHzYqR56NfFEoV7EmLUxOH87Q+pIRET0NxYiolIikwmY168xWtV0QXa+DkPDo5GQliN1LCIiAgsRUalSKmRY8rYf6nk4IDVTi5BVUXiQnS91LCIii8dCRFTK1NZWCB/aAp6O1riemo0RP55AXgEnbiQikhILEZEEPBytET6sBdTWCsTcfIB3N5yCTs85ioiIpMJCRCSROu4OWB7SHEqFDH9cTMZMTtxIRCQZFiIiCbXwdsa3bzaBIABrjt/E4kOcuJGISAosREQS69qwEqZ39wUAzPuNEzcSEUmBhYjIDAxt7Y3R7ThxIxGRVFiIiMzEh53roScnbiQikgQLEZGZkMkEfNmvMVrXejhx45BV0bh1nxM3EhGVBkEs5mUtEydOfPIbCQKsra1Rq1Yt9OzZE87OziYJaA40Gg0cHR2RkZEBtVotdRwq5zLzCtB/6XFcuquBt6sdfh7TCs52SqljERGVOcX5/S52IerQoQNOnjwJnU6HunXrAgAuX74MuVyOevXqIS4uDoIg4MiRI/D19X3xb2FGWIiotCVr8tBn0THcTs9FEy8nrB8ZAFulQupYRERlSnF+v4t9yKxnz54ICgrCnTt3EBMTg5iYGCQmJuK1117DwIEDcfv2bbRr1w7vv//+C38BIkvnrrbG6mEt4GRrhdMJ6Ri//hQKdXqpYxERlVvF3kNUuXJl7N2797G9PxcuXEDHjh1x+/ZtnDx5Eh07dsS9e/dMGlYq3ENEUom5mYa3foiEtlCPN/298EXfhhAEQepYRERlQonuIcrIyEBKSspjy1NTU6HRaAAATk5OyM/nDSuJXpZfNWcsGNgUMgHYdCIB//vzitSRiIjKpRc6ZDZs2DBs27YNiYmJSExMxLZt2zB8+HD06tULABAVFYU6deqYOiuRRepY3wOf9WoAAJi/7wrWRd6UOBERUflT7ENmWVlZeP/99/Hjjz+isLAQAKBQKBASEoL//e9/sLOzw+nTpwEATZo0MXVeSfCQGZmDb/6Iw/z9VyETgCWD/NCxvofUkYiIzFqJXmX2SFZWFq5fvw4AqFGjBuzt7V/kbcoEFiIyB6IoYsrP57DpRAJUChnWjwyAX7XyM70FEZGpleg5RI/Y29ujUaNGaNSoUbkuQ0TmQhAEzO7dAK/Wc4O2UI/hq0/gakqm1LGIiMqFYhei7OxsTJs2Da1atUKtWrVQo0YNowcRlRyFXIYFbzVFEy8npOcUIGRlNJIy8qSORURU5hW7EI0YMQIrVqxA27ZtMW7cOLz33ntGD1O7ffs2Bg0aBBcXF9jY2KBhw4Y4ceKEYb0oipg+fToqVaoEGxsbBAUF4coV4ytx0tLSEBwcDLVaDScnJwwfPhxZWVkmz0pUGmyVCqwc0hw1XO1wOz0XQ1ZFISO3QOpYRERlWrHPIXJycsLu3bvRunXrkspk8ODBAzRt2hQdOnTAmDFjULFiRVy5cgU1a9ZEzZo1AQBz585FWFgYVq9eDW9vb0ybNg3nzp3DxYsXYW1tDQDo0qUL7t69i6VLl6KgoABDhw5F8+bNsX79+iLl4DlEZI4S0nLQZ/ExpGZqEeDtjNXDWsDaSi51LCIis1GiJ1V7e3vj119/hY+Pz0uFLIopU6bg6NGj+Ouvv564XhRFeHp6YtKkSZg8eTKAh/Mkubu7Izw8HAMGDMClS5fg6+uL6Oho+Pv7AwB+++03dO3aFYmJifD09HxuDhYiMlcX7mTgzaXHkaUtRNeGHlgwsBnkMk7cSEQElPBJ1Z999hmmT5+OnJySvwv3jh074O/vjzfeeANubm5o2rQpfvjhB8P6+Ph4JCUlISgoyLDM0dERAQEBiIiIAABERETAycnJUIYAICgoCDKZDJGRkU/8XK1WC41GY/QgMkf1PR2x7G0/WMkF/HouCZ/uvIAXvHCUiMiiFbsQff311/j999/h7u6Ohg0bolmzZkYPU7p+/ToWL16M2rVr4/fff8eYMWPw7rvvYvXq1QCApKQkAIC7u7vR69zd3Q3rkpKS4ObmZrReoVDA2dnZMObfwsLC4OjoaHh4eXmZ9HsRmVKrWq74pn8TAMDqiJtYdPCatIGIiMqgYt8++9Fs1KVBr9fD398fc+bMAQA0bdoU58+fx5IlSxASElJinzt16lRMnDjR8Fyj0bAUkVnr0dgTqZlafLrrIr78PQ5uDiq84c//zRIRFVWxC9GMGTNKIscTVapU6bGbyPr4+ODnn38GAHh4PJypNzk5GZUqVTKMSU5ONsyS7eHh8di91woLC5GWlmZ4/b+pVCqoVCpTfQ2iUjGsjTdSMrVYcugapmw9B1d7FTrUc3v+C4mI6MUnZiwNrVu3RlxcnNGyy5cvo1q1agAenuDt4eGBffv2GdZrNBpERkYiMDAQABAYGIj09HTExMQYxuzfvx96vR4BAQGl8C2ISs+HneuiT7PK0OlFjF13EqduPZA6EhFRmVCkQuTs7Ix79+4BACpUqABnZ+enPkzp/fffx/HjxzFnzhxcvXoV69evx7JlyxAaGgrg4cy9EyZMwOeff44dO3bg3LlzGDx4MDw9PQ2H9nx8fNC5c2eMHDkSUVFROHr0KMaNG4cBAwYU6QozorJEEATM7dsI7etURG6BDsPCo3E1hXNuERE9T5Euu1+9ejUGDBgAlUqF8PBwCMLTL+s19bk9u3btwtSpU3HlyhV4e3tj4sSJGDlypGG9KIqYMWMGli1bhvT0dLRp0waLFi1CnTp1DGPS0tIwbtw47Ny5EzKZDH379sX8+fOLfMsRXnZPZU22thBv/XAcZxIzUNnJBj+PaQUPR2upYxERlapSubmrJWEhorLofpYW/ZZEIP5eNuq6O2DzO4FwtLGSOhYRUakp0XmI5HL5YycpA8D9+/chl3OWXCJz4WKvwo/DWqCigwpxyZkYufoEcvN1yNYWIjVTi5v3s3EvSyt1TCIis1Dsq8yetkNJq9VCqVS+dCAiMh0vZ1usHtoCby6NQNSNNPhM/81ovVwmYFo3Hwxp7S1RQiIi81DkQjR//nwAD0/aXL58udH5NzqdDocPH0a9evVMn5CIXoqvpxrLBvtj9JoT0OQVAgAEAbBWyJFboMPMnRfhbK/C6415kQERWa4in0Pk7f3wX5A3b95ElSpVjA6PKZVKVK9eHZ9++mm5vJSd5xBReZBXoEOWthB2SgWsrR4eLZ+18yLCj92AlVzAyiHN0bZ2RYlTEhGZTomeVN2hQwds3boVFSpUeKmQZQkLEZVXer2I8RtPYffZu7BVyrFxVEs0quIkdSwiIpMo0ZOqDxw4YFFliKg8k8kEfNO/MVrXckFOvg5DVkXjeirnLSIiy/NCl90nJiZix44duHXrFvLz843WffPNNyYLZy64h4jKuyxtIQYsi8D52xpUqfBw3iJ3NectIqKyrTi/38W+ymzfvn14/fXXUaNGDcTGxqJBgwa4ceMGRFE0+d3uiah02KsUCB/aAv0WH8ON+zkIWRmFTaM5bxERWY5iHzKbOnUqJk+ejHPnzsHa2ho///wzEhIS0L59e7zxxhslkZGISoGrvQo/DgtARQcVYpMezluUV6CTOhYRUakodiG6dOkSBg8eDABQKBTIzc2Fvb09Pv30U8ydO9fkAYmo9FR1eThvkYNKgagbaRi/4RQKdXqpYxERlbhiFyI7OzvDeUOVKlXCtWvXDOse3QCWiMouX081lof4Q6mQYe/FZHy87fxTJ2QlIiovil2IWrZsiSNHjgAAunbtikmTJmH27NkYNmwYWrZsafKARFT6Amq4YMHAppAJwKYTCfjy9zipIxERlahiF6JvvvnGMPnirFmz8Oqrr2LTpk2oXr06VqxYYfKARCSNTvU9MKd3QwDAooPXsOJIvMSJiIhKTrGuMtPpdEhMTESjRo0APDx8tmTJkhIJRkTSG9CiKu5n5+PL3+Pw2a6LcLazQu+mVaSORURkcsXaQySXy9GxY0c8ePCgpPIQkZkZ+0pNDPv75q8fbDmLA7EpEiciIjK9Yh8ya9CgAa5fv14SWYjIDAmCgE+6+aB308oo1IsYsy4GMTfTpI5FRGRSxS5En3/+OSZPnoxdu3bh7t270Gg0Rg8iKn9kMgHz+jVCh7oVkVegx9BV0YhN4p93Iio/in3rDpns/zuUIAiG/xZFEYIgQKcrfxO58dYdRA/l5uswaEUkYm4+gJuDCj+PaQUvZ1upYxERPVGJ3rrjwIEDLxyMiMo2G6UcK0Oao//SCMQlZ+LtFZHY8k4rVHRQSR2NiOilvNDNXS0N9xARGUvW5KHv4mNIfJAL30pqbBzdEmpr3veMiMxLcX6/WYiKgIWI6HE37mWj35JjuJeVjxbezninfQ2k5xQgI/fho7qLHV5v7AmZTHj+mxERlYASPWRGRAQA1V3tsHpYCwxYehxR8WmIin/8yrPztzPwcTcfo/MNiYjMEQsREb2w+p6OWDW0Ob7YE4t8nR6ONlZQ21hBIRPwy+k7WH4kHhXslAjtUEvqqEREz8RCREQvxb+6M34a0+qx5Q0rO+Lz3Zfw5e9xcLSxwqCW1SRIR0RUNC9ciFJTUxEX9/CGj3Xr1kXFihVNFoqIyr4RbR+eU7TwwFVM++U8HG2s0KOxp9SxiIieqNgTM2ZnZ2PYsGHw9PREu3bt0K5dO3h6emL48OHIyckpiYxEVEZN6lgHwQFVIYrAxM2ncTCOt/0gIvNU7EI0ceJEHDp0CDt27EB6ejrS09Pxyy+/4NChQ5g0aVJJZCSiMkoQBHzaswG6N6qEAp2Id9bG4MQN3vaDiMxPsS+7d3V1xU8//YRXXnnFaPmBAwfQv39/pKammjKfWeBl90QvJ79Qj5E/nsChy6lwsFZg06hA+HryzxIRlazi/H4Xew9RTk4O3N3dH1vu5ubGQ2ZE9ERKhQxLBvnBv1oFZOYVYvDKKMTfy5Y6FhGRQbELUWBgIGbMmIG8vDzDstzcXMyaNQuBgYEmDUdE5YeNUo4VQ5rDt5Ia97K0GLQ8Enczcg3rC3V6ZOQUSJiQiCxZsQ+ZnT9/Hp06dYJWq0Xjxo0BAGfOnIG1tTV+//131K9fv0SCSomHzIhMJzVTi/5LIxB/LxsVHVRwsFYgLTsfGbkFEEWgdS0XLHvbH3YqzgpCRC+nxG/dkZOTg3Xr1iE2NhYA4OPjg+DgYNjY2LxYYjPHQkRkWokPcvDGkgjczch74vo2tVyxYog/VAp5KScjovKE9zIzMRYiItPLyC1A5PX7cLC2gou9Es52Sty8n423V0QhJ1+HTvXd8f1bzaCQF/vIPhERgBIoRDt27Cjyh7/++utFHltWsBARlZ5jV+9hSHg08gv16NOsMr7q15g3iCWiF2LyQiSTFe1faIIgQKfTFS1lGcJCRFS6/riQhDHrTkKnFzGkVXXM6OHLG8QSUbGZ/LJ7vV5fpEd5LENEVPo61vfAV280AgCEH7uBr/+4LHEiIirveHCeiMxS76ZV8FnPh1etLjxwFUsOXZM4ERGVZ0UuRF27dkVGRobh+RdffIH09HTD8/v378PX19ek4YjIsr0dWB0fdq4HAPhiTyzWHr8pcSIiKq+KXIh+//13aLVaw/M5c+YgLe3/70lUWFiIuLg406YjIos35pWaCO1QEwAw7Zfz2HYqUeJERFQeFbkQ/fvca16tT0SlZXLHuhjSqjpEEZi85Sx+v5AkdSQiKmd4DhERmT1BEDC9uy/6+VWBTi9i/PpTOHS5/N1ImoikU+RCJAjCY5e9lvZlsF988QUEQcCECRMMy/Ly8hAaGgoXFxfY29ujb9++SE5ONnrdrVu30K1bN9ja2sLNzQ0ffPABCgsLSzU7Eb0cmUzAF30aomtDD+Tr9Bi95gQir9+XOhYRlRNFvlmQKIoYMmQIVCoVgIdF5J133oGdnR0AGJ1fVBKio6OxdOlSNGrUyGj5+++/j927d2PLli1wdHTEuHHj0KdPHxw9ehQAoNPp0K1bN3h4eODYsWO4e/cuBg8eDCsrK8yZM6dEMxORaSnkMnz7ZlPk5p/AgbhUDF99AmtHBKCJl5PU0YiojCvyrTuGDh1apDdctWrVSwV6kqysLDRr1gyLFi3C559/jiZNmuDbb79FRkYGKlasiPXr16Nfv34AgNjYWPj4+CAiIgItW7bEnj170L17d9y5cwfu7u4AgCVLluDDDz9EamoqlErlcz+fEzMSmZe8Ah2GhUfj2LX7cLSxwsZRLeFT6eGfzUKdHimZWrjaq6BU8KwAIktWnN/vIu8hKomiU1ShoaHo1q0bgoKC8PnnnxuWx8TEoKCgAEFBQYZl9erVQ9WqVQ2FKCIiAg0bNjSUIQDo1KkTxowZgwsXLqBp06al+l2I6OVZW8nxw2B/vL0iEidvpWPgD8dRzcUOSRm5SM3UQi8CFR1UWDO8Bep58B8xRPR8Zv/Pp40bN+LkyZMICwt7bF1SUhKUSiWcnJyMlru7uyMpKckw5p9l6NH6R+ueRKvVQqPRGD2IyLzYqRRYNbQF6nuqkZ5TgDMJ6UjWPCxDAJCaqcWg5ZG4lpolbVAiKhOKvIdICgkJCXjvvfewd+9eWFtbl9rnhoWFYdasWaX2eUT0YhxtrLBpdCD2x6ZApZChkqM1PBytYSWTIXh5JC7e1SD4h0hsHh2Iqi62UsclIjNm1nuIYmJikJKSgmbNmkGhUEChUODQoUOYP38+FAoF3N3dkZ+fbzRjNgAkJyfDw8MDAODh4fHYVWePnj8a829Tp05FRkaG4ZGQkGD6L0dEJmGvUuD1xp7oVN8Djao4wc3BGhXslFgzvAVqu9kjSZOHt5Yfx530XKmjEpEZM+tC9Oqrr+LcuXM4ffq04eHv74/g4GDDf1tZWWHfvn2G18TFxeHWrVsIDAwEAAQGBuLcuXNISUkxjNm7dy/UavVTbzWiUqmgVquNHkRUtrjYq7BuRACqu9gi8UEu3vrhOFI0eVLHIiIzZdaHzBwcHNCgQQOjZXZ2dnBxcTEsHz58OCZOnAhnZ2eo1WqMHz8egYGBaNmyJQCgY8eO8PX1xdtvv4158+YhKSkJn3zyCUJDQw1TCBBR+eSmtsa6kS3Rf0kEbtzPwVvLI7FxVEu42vPPPhEZM+s9REXxv//9D927d0ffvn3Rrl07eHh4YOvWrYb1crkcu3btglwuR2BgIAYNGoTBgwfj008/lTA1EZWWyk422DCyJTzU1riakoVByyPxIDtf6lhEZGaKPA+RJeM8RERl3/XULLy57DhSM7VoUFmNdSNawtHGSupYRFSCivP7Xeb3EBERFUWNivZYPyIALnZKnL+tQcjKKGTmFUgdi4jMBAsREVmM2u4OWDsiAE62VjidkI5h4dHI1vK+hkTEQkREFsankhprhwfAwVqB6BsPMCw8Gjn5LEVElo6FiIgsToPKjvhxWAvYqxSIjE/DiNUnkJuvkzoWEUmIhYiILFLTqhWwelhz2CnlOHbtPkatOYG8ApYiIkvFQkREFsuvmjPCh7WArVKOv67cw+g1MdAWshQRWSIWIiKyaM2rO2PlkOawtpLh0OVUjFl7kqWIyAKxEBGRxWtZwwUrQ5pDpZBhf2wKQtexFBFZGhYiIiIArWq5YuWQh6Xoz0sPS1F+oV7qWERUSliIiIj+1rqWK1aE/H8pGstSRGQxWIiIiP6hTW1X/DDYH0qFDH9eSkboepYiIkvAQkRE9C/t6lTE8r9L0d6LLEVEloCFiIjoCdrVqWjYU7T3YjLGruMl+UTlGQsREdFTtP97T9Gjc4p4ST5R+cVCRET0DO3qVMSKkIfzFO2PTcE7a2I4ozVROcRCRET0HG1qu2Ll36XoQFwqRrEUEZU7LEREREXQqpYrVg1pARsrOQ5fTsXw1dG8ISxROcJCRERURIE1XbB6WAvYKeU4evU+hqyKQra2UOpYRGQCLERERMXQwtsZPw5vAQeVApHxaQhZGYXMvAKpYxHRS2IhIiIqJr9qzlgzIgBqawVO3HyAt1dEISOXpYioLGMhIiJ6AU28nLB+ZEs42VrhdEI6gpcfx4PsfKljEdELYiEiInpBDSo7YsPIlnCxU+L8bQ0GLDuO1Eyt1LGI6AWwEBERvQSfSmpsGt0Sbg4qxCVn4s2lEbibkSt1LCIqJhYiIqKXVMvNAZtHB6Kykw2u38tG/6URSEjLkToWERUDCxERkQlUd7XDptEtUc3FFglpuei/NALXU7OkjkVERcRCRERkIlUq2GLz6EDUrGiHuxl56L80AhfvaKSORURFwEJERGRC7mprbB4dCN9KatzLyseAZRE4eeuB1LGI6DlYiIiITMzFXoUNo1qiWVUnaPIKMWh5JI5duyd1LCJ6BhYiIqIS4GhjhTXDA9C6lgty8nUYsioa+y4lSx2LiJ6ChYiIqITYqRRYEdIcQT7uyC/UY/SaGPxy+rbUsYjoCViIiIhKkLWVHIsHNUPvppVRqBcxYdNprIm4IXUsIvoXFiIiohJmJZfh6zcaY3BgNYgiMO2XC1i4/wpEUZQ6GhH9jYWIiKgUyGQCZr1eH+/+pxYA4Ks/LmP27kvQ61mKiMwBCxERUSkRBAETO9bFJ918AADLj8Tjg5/OokCnlzgZEbEQERGVshFta+CrNxpDLhPw88lEvLMmBrn5OqljEVk0FiIiIgn086uCpYP8oFLIsC82BYNXRiIjp0DqWEQWi4WIiEgiQb7uWDsiAA7WCkTfeID+SyOQrMmTOhaRRWIhIiKSUPPqztg8OhBuDirEJWeiz6JjuJrCm8ISlTYWIiIiiflUUuPnMa3g7WqH2+m56LfkGGJu8v5nRKWJhYiIyAx4Odvip3cC0djLCek5BQhefhx/Xvz/W31k5BTgt/N3EfbrJd4slqgECCJnBnsujUYDR0dHZGRkQK1WSx2HiMqxnPxChK47iQNxqZAJQH9/L1xKysS5xHQ8mrJIKZfhmzcbo3sjT2nDEpm54vx+cw8REZEZsVUqsGywP/r5VYFeBDZGJ+BMwsMyVLOiHfyqVUC+To9x609h+V/XpY5LVG6YdSEKCwtD8+bN4eDgADc3N/Tq1QtxcXFGY/Ly8hAaGgoXFxfY29ujb9++SE42vqP0rVu30K1bN9ja2sLNzQ0ffPABCgsLS/OrEBEVmZVchi/7NcLHXX3Qp1llfNmvESKm/gf7Jr2CzaMDMaRVdQDA57sv4dOdFznbNZEJmHUhOnToEEJDQ3H8+HHs3bsXBQUF6NixI7Kzsw1j3n//fezcuRNbtmzBoUOHcOfOHfTp08ewXqfToVu3bsjPz8exY8ewevVqhIeHY/r06VJ8JSKiIhEEASPb1cA3/ZvgDX8vVHK0AQDIZQJm9PDF1C71AAArj8Zj3IaTyCvgxI5EL6NMnUOUmpoKNzc3HDp0CO3atUNGRgYqVqyI9evXo1+/fgCA2NhY+Pj4ICIiAi1btsSePXvQvXt33LlzB+7u7gCAJUuW4MMPP0RqaiqUSuVzP5fnEBGROfrl9G1M3nIGBToRftUq4IfB/nC2e/7faUSWotyeQ5SRkQEAcHZ2BgDExMSgoKAAQUFBhjH16tVD1apVERERAQCIiIhAw4YNDWUIADp16gSNRoMLFy488XO0Wi00Go3Rg4jI3PRsUhmrh7WAg7UCMTcfoM+io4i/l/38FxLRY8pMIdLr9ZgwYQJat26NBg0aAACSkpKgVCrh5ORkNNbd3R1JSUmGMf8sQ4/WP1r3JGFhYXB0dDQ8vLy8TPxtiIhMo1VNV2wd0wqVnWxw434Oei86iugbaRBFERfuZGDBvivo+f1R+H/+J/acuyt1XCKzpZA6QFGFhobi/PnzOHLkSIl/1tSpUzFx4kTDc41Gw1JERGartrsDtoW2wsjVJ3AmMQPBP0TC1V6JOxnGtwEZs+4kPuxcD++0rwFBECRKS2SeysQeonHjxmHXrl04cOAAqlSpYlju4eGB/Px8pKenG41PTk6Gh4eHYcy/rzp79PzRmH9TqVRQq9VGDyIic+bmYI2NowLxmq878nV63MnIg7WVDEE+7gjr0xAhgdUAAHN/i8WUn8+hQKc3vDa/UI9Dl1Ox9NA13M/SSvUViCRl1nuIRFHE+PHjsW3bNhw8eBDe3t5G6/38/GBlZYV9+/ahb9++AIC4uDjcunULgYGBAIDAwEDMnj0bKSkpcHNzAwDs3bsXarUavr6+pfuFiIhKkI1SjiWD/LDjzG042lihVU1XWFvJDeu9Xe3w6a6L2HQiAQkPcvBmcy/8eSkFB2NTkKl9OBXJmuM3sXJIc9Rxd5DqaxBJwqyvMhs7dizWr1+PX375BXXr1jUsd3R0hI3Nw0tQx4wZg19//RXh4eFQq9UYP348AODYsWMAHl5236RJE3h6emLevHlISkrC22+/jREjRmDOnDlFysGrzIiovNgfm4zx608hO9/4Mv2KDiooZALuZuTBQaXAgrea4pW6bhKlJDKN4vx+m3Uhetox7lWrVmHIkCEAHk7MOGnSJGzYsAFarRadOnXCokWLjA6H3bx5E2PGjMHBgwdhZ2eHkJAQfPHFF1AoiraDjIWIiMqTi3c0GLfhJACgo68HOtZ3R5MqTsjILcDotTGIik+DTABm9KiPkL8ngSQqi8pNITIXLEREZCnyC/X4eNs5bIlJBAC83bIapvfwhZW8TJxySmSk3M5DREREJUupkGFev0aY0qUeBOHhOUUhK6PwIDtf6mhEJYqFiIiIjAiCgHfa18TSQX6wU8px7Np99Fp0FJeTM43GZWkL8cvp29h6MpH3U6Myj4fMioCHzIjIUsUmaTBi9QkkPsiFvUqBL/s1AgDsOHMH+2NToC18ePl+5/oe+Lp/Y9ipzPriZbIwPIfIxFiIiMiSpWXnY8zaGETGpz22rrqLLW6n56JAJ6KehwOWve2Pqi62EqQkehzPISIiIpNxtlNi7YgADGpZFQBQ2ckGo9vXwK7xbXBg8ivYOKolXO1ViE3KxOvfH8HRq/ckTkxUfNxDVATcQ0RE9NC9LC1c7JSPTYtyNyMXo9fE4GxiBuQyAVO71MPwNt68RQhJinuIiIioRLjaq55Ycio52mDz6ED0aVoZOr2Iz3dfwoRNp5H7rwkgicwVCxEREZmEtZUcX/dvjOndfSGXCfjl9B30XnQUt+7nSB2N6LlYiIiIyGQEQcCwNt5YNyIArvZKxCZlosfCIzgYlyJ1NKJnYiEiIiKTa1nDBTvHt0ETr4e3BBkaHo3v/rzC+YrIbLEQERFRiajkaINNo1tiYIuqEEXgf39exrDV0Zz1mswSCxEREZUYlUKOsD4N8WW/RlApZDgYl4ruC47gbGK61NGIjLAQERFRiXvD3wvbxrZGtb8ncuy3OAJrj98EZ34hc8FCREREpcLXU40d49rgNV935Ov0+GT7eby78TSytIVSRyNiISIiotLjaGOFZW/74aOu9SCXCdh55g56LDiCi3c0UkcjC8dCREREpUoQBIxqVxObR7dEJUdrxN/LRq9FR7E+8hYPoZFkWIiIiEgSftWc8eu7bdGhbkXkF+rx0bZzGL/hFDR5BVJHIwvEQkRERJKpYKfEipDmmNLl4SG0XWfvotv8v3A6IV3qaGRhWIiIiEhSMpmAd9rXxJZ3AlGlgg0S0nLRb/ExLD10jRM5UqlhISIiIrPQrGoF7H63Lbo1qoRCvYiwPbEIWRWFFE2e1NHIArAQERGR2XC0scLCgU3xRZ+GsLaS4a8r99D5u7+w92Ky1NGonGMhIiIisyIIAga0qIpd49vAt5Iaadn5GPnjCXy87Rxy83VSx6NyioWIiIjMUi03B2wLbYWRbb0BAOsib6H7gr9w/naGxMmoPGIhIiIis6VSyPFxN1+sHR4ANwcVrqVmo9f3R7Fw/xUU6vRSx6NyhIWIiIjMXpvarvhtQjt0aeCBQr2Ir/64jP5LI3DjXrbU0aicYCEiIqIywdlOiUXBzfBN/8ZwUClw8lY6us7/C+sieZNYenksREREVGYIgoA+zapgz4S2aFnDGTn5Ony87TwGr4zCnfRcqeNRGcZCREREZU6VCrZYP6IlPunmA5Xi4eX5nf53GFtOJHBvEb0QFiIiIiqTZDIBI9rWwO5326KJlxMytYX44KezGLH6BJI5mSMVEwsRERGVabXc7PHTO4H4sHM9KOUy7ItNQdA3h7D5CXuL9HoRO8/cwdsrIrH8r+vQPePWICmZecgv5JVslkIQuW/xuTQaDRwdHZGRkQG1Wi11HCIieorLyZn4YMsZnEl8OFdR29quCOvTEJWdbPD7hST8b+8VxCVnGsY3ruKIef0ao66Hg2HZ1ZRM/O/PK9h99i6qOtviiz4N0aqWa6l/F3p5xfn9ZiEqAhYiIqKyo1Cnx4oj8fhm72VoC/WwU8rh5WyL2KSHRcjBWoHXG3tix5k7yMwrhJVcQGiHWujeyBOLDl7F9lO38e8dRwOae2FqVx842lhJ8I3oRbEQmRgLERFR2XM9NQsf/nwW0TceAADslHIMa+ONEW1qwNHWCsmaPHy87Tz+vPT4fdI6+rpjdPua2H7qNtYcvwkAcHNQ4bNeDdCpvkepfg96cSxEJsZCRERUNun1IrbEJCBFo0Vwy2pwtlMarRdFEbvO3sXMHRdwPzsf7etUxMTX6qCxl5NhTFR8Gqb8fBbX/54EslN9d8x6vQE8HK1L86vQC2AhMjEWIiKi8k2TV4AUjRa13OyfuD6vQIf5+65g6eGHJ2LbqxT4oFNdDGpZDXKZUMppqahYiEyMhYiIiADg0l0Npm49h9MJ6QCAJl5OmNO7IXw9+dtgjorz+83L7omIiIrIp5IaP49phU971oe9SoHTCenosfAIPtt1EVnaQqnj0UtgISIiIioGuUzA4MDq+HNie3Rp4AGdXsSKI/F49euD2H32LmfKLqNYiIiIiF6Ah6M1Fg/yw6qhzVHV2RbJGi1C159EyKpoxP99AvaTJGvy8GPEDSQ+yCnFtPQ8PIeoCHgOERERPUtegQ6LDl7DkoPXkK/TQymXYXhbb4zrUAt2KoVhzPK/rmPRwWvIyddBpZAhtEMtjGpXA9ZWcom/QfnEk6pNjIWIiIiKIv5eNmbuuIBDl1MBAB5qa3zczQcA8MWeWNxOzwUAuNqrcC9LCwCo6myLad19EeTjBkHgFWumxJOqn+L7779H9erVYW1tjYCAAERFRUkdiYiIyhFvVzuED22OHwb7w8vZBkmaPIzfcArjN5zC7fRceDpa47sBTRD10atYMLApPNTWuJWWg5E/nsCQVdG4mpIl9VewWBazh2jTpk0YPHgwlixZgoCAAHz77bfYsmUL4uLi4Obm9szXcg8REREVV16BDssOX8f3B65CJggY80pNjGxbAzbK/z88lq0txMIDV7H8r+so0IlQyAS8HVgNE16tA0db3ibkZfGQ2RMEBASgefPmWLhwIQBAr9fDy8sL48ePx5QpU575WhYiIiJ6UWnZ+ZAJgJOt8qlj4u9lY/buS4bbiFSwtcLEjnUxsLkXFHKLOphjUjxk9i/5+fmIiYlBUFCQYZlMJkNQUBAiIiIeG6/VaqHRaIweREREL8LZTvnMMgQ8PNS2PMQfa4a3QG03ezzIKcC07efRdf5fOBiXUkpJLZtFFKJ79+5Bp9PB3d3daLm7uzuSkpIeGx8WFgZHR0fDw8vLq7SiEhGRBWtbuyL2vNcWs16vDydbK1xOzsKQVdF4e0UkYpP4j/OSZBGFqLimTp2KjIwMwyMhIUHqSEREZCEUchlCWlXHockdMKKNN6zkAv66cg9dv/sLU34+i2RNntQRyyWLKESurq6Qy+VITk42Wp6cnAwPD4/HxqtUKqjVaqMHERFRaXK0tcIn3X3x58T26NrQA3oR2BidgPZfHsBXv8chM69A6ojlikUUIqVSCT8/P+zbt8+wTK/XY9++fQgMDJQwGRER0bNVc7HDomA//DwmEH7VKiCvQI+FB66i/ZcHsepoPPIL9VJHLBcs5iqzTZs2ISQkBEuXLkWLFi3w7bffYvPmzYiNjX3s3KJ/41VmRERkDkRRxO8XkjHv91hcT314exAvZxu8H1QHPZtUhlzGiR3/iZfdP8XChQvx5ZdfIikpCU2aNMH8+fMREBDw3NexEBERkTkp1Omx6UQCvv3zClIzH854XdfdAZM61sFrvu6c8fpvLEQmxkJERETmKCe/EKuP3cTig1ehySsEADTxcsLkjnXRupaLxRcjFiITYyEiIiJzlpFbgGWHr2HlkRvILdABAFp4O2PSa3UQUMNF4nTSYSEyMRYiIiIqC1Iy87DowDWsj7yFfN3Dk63b1nbF+6/VQbOqFSROV/pYiEyMhYiIiMqSuxm5WLj/KjZFJ6BQ//Bnvl2dinjv1drwq2Y5xYiFyMRYiIiIqCxKSMvB/H1XsPXUbej+LkZta7tiQlBt+FVzljhdyWMhMjEWIiIiKstu3c/B9weu4ueTiYY9Rq1ruWBch9poWcO53J58zUJkYixERERUHiSkPSxGP8X8fzHyq1YB4/5TC6/UqVjuihELkYmxEBERUXmS+CAHyw5fx8boBMNM1w0qqzGmfS10buBRbiZ4ZCEyMRYiIiIqj1I0efjhr+tYF3kLOfkPL9f3drXD6HY10LtZZagUcokTvhwWIhNjISIiovIsLTsfq4/dQPixG8jIfXjTWHe1CkNbe+OtgKpQW1tJnPDFsBCZGAsRERFZgmxtITZE3cLyv+KRpMkDANirFHgroCqGtq6OSo42EicsHhYiE2MhIiIiS6It1OGX03fww+HruJKSBQBQyAS83sQTw9t4o76no8QJi4aFyMRYiIiIyBLp9SIOXk7B0kPXERmfZljeqqYLhrfxRoe6bpCZ8QnYLEQmxkJERESW7kxCOpYficev5+4aJnms4WqHoa2ro0+zKrBTKSRO+DgWIhNjISIiInrodnoufjx2A+ujbiEzrxAA4GCtwIDmXhgcWB1ezrYSJ/x/LEQmxkJERERkLEtbiJ9OJCD82A3cuJ8DAJAJQJCPO0JaVUermi6ST/TIQmRiLERERERP9ug8o1VHb+CvK/cMy2u52WNwYDX0aVYF9hIdTmMhMjEWIiIioue7kpyJHyNu4ueTiYaJHu1VCvRuWhmDWlZDXQ+HUs3DQmRiLERERERFp8krwNaYRPx4/Caup2YbljevXgGDWlZD5wYepTILNguRibEQERERFZ8oijh69T7WHr+JvZeSDVenudgp0c+vCga0qApvV7sS+3wWIhNjISIiIno5SRl52BSdgA1RtwyzYANAYA0XDAyoik713U2+14iFyMRYiIiIiEyjUKfHgbhUbIi6hQNxKXjUQpztlDgw6RU42pruvmnF+f02v1mUiIiIqNxSyGV4zdcdr/m643Z6LjZFJ2BzdAKqu9qatAwVF/cQFQH3EBEREZWcQp0e97Pz4a62Nun7Fuf3W2bSTyYiIiIqJoVcZvIyVFwsRERERGTxWIiIiIjI4rEQERERkcVjISIiIiKLx0JEREREFo+FiIiIiCweCxERERFZPBYiIiIisngsRERERGTxWIiIiIjI4rEQERERkcVjISIiIiKLx0JEREREFk8hdYCyQBRFAIBGo5E4CRERERXVo9/tR7/jz8JCVASZmZkAAC8vL4mTEBERUXFlZmbC0dHxmWMEsSi1ycLp9XrcuXMHDg4OEAThhd9Ho9HAy8sLCQkJUKvVJkxI/8ZtXbq4vUsPt3Xp4bYuPSW1rUVRRGZmJjw9PSGTPfssIe4hKgKZTIYqVaqY7P3UajX/cJUSbuvSxe1deritSw+3dekpiW39vD1Dj/CkaiIiIrJ4LERERERk8ViISpFKpcKMGTOgUqmkjlLucVuXLm7v0sNtXXq4rUuPOWxrnlRNREREFo97iIiIiMjisRARERGRxWMhIiIiIovHQkREREQWj4WoFH3//feoXr06rK2tERAQgKioKKkjlXlhYWFo3rw5HBwc4Obmhl69eiEuLs5oTF5eHkJDQ+Hi4gJ7e3v07dsXycnJEiUuP7744gsIgoAJEyYYlnFbm87t27cxaNAguLi4wMbGBg0bNsSJEycM60VRxPTp01GpUiXY2NggKCgIV65ckTBx2aTT6TBt2jR4e3vDxsYGNWvWxGeffWZ07ytu6xdz+PBh9OjRA56enhAEAdu3bzdaX5TtmpaWhuDgYKjVajg5OWH48OHIysoqkbwsRKVk06ZNmDhxImbMmIGTJ0+icePG6NSpE1JSUqSOVqYdOnQIoaGhOH78OPbu3YuCggJ07NgR2dnZhjHvv/8+du7ciS1btuDQoUO4c+cO+vTpI2Hqsi86OhpLly5Fo0aNjJZzW5vGgwcP0Lp1a1hZWWHPnj24ePEivv76a1SoUMEwZt68eZg/fz6WLFmCyMhI2NnZoVOnTsjLy5Mwedkzd+5cLF68GAsXLsSlS5cwd+5czJs3DwsWLDCM4bZ+MdnZ2WjcuDG+//77J64vynYNDg7GhQsXsHfvXuzatQuHDx/GqFGjSiawSKWiRYsWYmhoqOG5TqcTPT09xbCwMAlTlT8pKSkiAPHQoUOiKIpienq6aGVlJW7ZssUw5tKlSyIAMSIiQqqYZVpmZqZYu3Ztce/evWL79u3F9957TxRFbmtT+vDDD8U2bdo8db1erxc9PDzEL7/80rAsPT1dVKlU4oYNG0ojYrnRrVs3cdiwYUbL+vTpIwYHB4uiyG1tKgDEbdu2GZ4XZbtevHhRBCBGR0cbxuzZs0cUBEG8ffu2yTNyD1EpyM/PR0xMDIKCggzLZDIZgoKCEBERIWGy8icjIwMA4OzsDACIiYlBQUGB0bavV68eqlatym3/gkJDQ9GtWzejbQpwW5vSjh074O/vjzfeeANubm5o2rQpfvjhB8P6+Ph4JCUlGW1rR0dHBAQEcFsXU6tWrbBv3z5cvnwZAHDmzBkcOXIEXbp0AcBtXVKKsl0jIiLg5OQEf39/w5igoCDIZDJERkaaPBNv7loK7t27B51OB3d3d6Pl7u7uiI2NlShV+aPX6zFhwgS0bt0aDRo0AAAkJSVBqVTCycnJaKy7uzuSkpIkSFm2bdy4ESdPnkR0dPRj67itTef69etYvHgxJk6ciI8++gjR0dF49913oVQqERISYtieT/o7hdu6eKZMmQKNRoN69epBLpdDp9Nh9uzZCA4OBgBu6xJSlO2alJQENzc3o/UKhQLOzs4lsu1ZiKjcCA0Nxfnz53HkyBGpo5RLCQkJeO+997B3715YW1tLHadc0+v18Pf3x5w5cwAATZs2xfnz57FkyRKEhIRInK582bx5M9atW4f169ejfv36OH36NCZMmABPT09uawvDQ2alwNXVFXK5/LGrbZKTk+Hh4SFRqvJl3Lhx2LVrFw4cOIAqVaoYlnt4eCA/Px/p6elG47ntiy8mJgYpKSlo1qwZFAoFFAoFDh06hPnz50OhUMDd3Z3b2kQqVaoEX19fo2U+Pj64desWABi2J/9OeXkffPABpkyZggEDBqBhw4Z4++238f777yMsLAwAt3VJKcp29fDweOzCo8LCQqSlpZXItmchKgVKpRJ+fn7Yt2+fYZler8e+ffsQGBgoYbKyTxRFjBs3Dtu2bcP+/fvh7e1ttN7Pzw9WVlZG2z4uLg63bt3iti+mV199FefOncPp06cND39/fwQHBxv+m9vaNFq3bv3Y9BGXL19GtWrVAADe3t7w8PAw2tYajQaRkZHc1sWUk5MDmcz4p1Aul0Ov1wPgti4pRdmugYGBSE9PR0xMjGHM/v37odfrERAQYPpQJj9Nm55o48aNokqlEsPDw8WLFy+Ko0aNEp2cnMSkpCSpo5VpY8aMER0dHcWDBw+Kd+/eNTxycnIMY9555x2xatWq4v79+8UTJ06IgYGBYmBgoISpy49/XmUmitzWphIVFSUqFApx9uzZ4pUrV8R169aJtra24tq1aw1jvvjiC9HJyUn85ZdfxLNnz4o9e/YUvb29xdzcXAmTlz0hISFi5cqVxV27donx8fHi1q1bRVdXV/G///2vYQy39YvJzMwUT506JZ46dUoEIH7zzTfiqVOnxJs3b4qiWLTt2rlzZ7Fp06ZiZGSkeOTIEbF27driwIEDSyQvC1EpWrBggVi1alVRqVSKLVq0EI8fPy51pDIPwBMfq1atMozJzc0Vx44dK1aoUEG0tbUVe/fuLd69e1e60OXIvwsRt7Xp7Ny5U2zQoIGoUqnEevXqicuWLTNar9frxWnTponu7u6iSqUSX331VTEuLk6itGWXRqMR33vvPbFq1aqitbW1WKNGDfHjjz8WtVqtYQy39Ys5cODAE/9+DgkJEUWxaNv1/v374sCBA0V7e3tRrVaLQ4cOFTMzM0skryCK/5iOk4iIiMgC8RwiIiIisngsRERERGTxWIiIiIjI4rEQERERkcVjISIiIiKLx0JEREREFo+FiIiIiCweCxERUSkTBAHbt2+XOgYR/QMLERG9tKSkJLz33nuoVasWrK2t4e7ujtatW2Px4sXIycmROh4R0XMppA5ARGXb9evX0bp1azg5OWHOnDlo2LAhVCoVzp07h2XLlqFy5cp4/fXXpY5Z7uXn50OpVEodg6jM4h4iInopY8eOhUKhwIkTJ9C/f3/4+PigRo0a6NmzJ3bv3o0ePXoYxn7zzTdo2LAh7Ozs4OXlhbFjxyIrK8uwPjw8HE5OTti1axfq1q0LW1tb9OvXDzk5OVi9ejWqV6+OChUq4N1334VOpzO8TqvVYvLkyahcuTLs7OwQEBCAgwcPPjO3IAhYvnw5evfuDVtbW9SuXRs7dux4LMs/bd++HYIgGJ7PnDkTTZo0wcqVK1G1alXY29tj7Nix0Ol0mDdvHjw8PODm5obZs2c/9vl3795Fly5dYGNjgxo1auCnn34yWp+QkID+/fvDyckJzs7O6NmzJ27cuGFYP2TIEPTq1QuzZ8+Gp6cn6tat+8zvS0TPxkJERC/s/v37+OOPPxAaGgo7O7snjvlngZDJZJg/fz4uXLiA1atXY//+/fjvf/9rND4nJwfz58/Hxo0b8dtvv+HgwYPo3bs3fv31V/z6669Ys2YNli5dalQgxo0bh4iICGzcuBFnz57FG2+8gc6dO+PKlSvPzD9r1iz0798fZ8+eRdeuXREcHIy0tLRibYNr165hz549+O2337BhwwasWLEC3bp1Q2JiIg4dOoS5c+fik08+QWRkpNHrpk2bhr59++LMmTMIDg7GgAEDcOnSJQBAQUEBOnXqBAcHB/z11184evQo7O3t0blzZ+Tn5xveY9++fYiLi8PevXuxa9euYuUmon8pkVvGEpFFOH78uAhA3Lp1q9FyFxcX0c7OTrSzsxP/+9//PvX1W7ZsEV1cXAzPV61aJQIQr169alg2evRo0dbW1ugO1506dRJHjx4tiqIo3rx5U5TL5eLt27eN3vvVV18Vp06d+tTPBiB+8sknhudZWVkiAHHPnj2GLI6Ojkav2bZtm/jPvzZnzJgh2traihqNxihb9erVRZ1OZ1hWt25dMSwszOiz33nnHaP3DggIEMeMGSOKoiiuWbNGrFu3rqjX6w3rtVqtaGNjI/7++++iKIpiSEiI6O7ubnRXdiJ6cTyHiIhMLioqCnq9HsHBwdBqtYblf/75J8LCwhAbGwuNRoPCwkLk5eUhJycHtra2AABbW1vUrFnT8Bp3d3dUr14d9vb2RstSUlIAAOfOnYNOp0OdOnWMMmi1Wri4uDwzZ6NGjQz/bWdnB7VabXjfoqpevTocHByMssnlcshkMqNl/37fwMDAx56fPn0aAHDmzBlcvXrV6H0BIC8vD9euXTM8b9iwIc8bIjIRFiIiemG1atWCIAiIi4szWl6jRg0AgI2NjWHZjRs30L17d4wZMwazZ8+Gs7Mzjhw5guHDhyM/P99QiKysrIzeSxCEJy7T6/UAgKysLMjlcsTExEAulxuN+2eJepJnva9MJoMoikbrCwoKivQez3rfosjKyoKfnx/WrVv32LqKFSsa/vtphymJqPhYiIjohbm4uOC1117DwoULMX78+Gf+QMfExECv1+Prr7827D3ZvHnzS2do2rQpdDodUlJS0LZt25d+v0cqVqyIzMxMZGdnG77Xoz04pnD8+HEMHjzY6HnTpk0BAM2aNcOmTZvg5uYGtVptss8koqfjSdVE9FIWLVqEwsJC+Pv7Y9OmTbh06RLi4uKwdu1axMbGGvba1KpVCwUFBViwYAGuX7+ONWvWYMmSJS/9+XXq1EFwcDAGDx6MrVu3Ij4+HlFRUQgLC8Pu3btf+H0DAgJga2uLjz76CNeuXcP69esRHh7+0nkf2bJlC1auXInLly9jxowZiIqKwrhx4wAAwcHBcHV1Rc+ePfHXX38hPj4eBw8exLvvvovExESTZSCi/8dCREQvpWbNmjh16hSCgoIwdepUNG7cGP7+/liwYAEmT56Mzz77DADQuHFjfPPNN5g7dy4aNGiAdevWISwszCQZVq1ahcGDB2PSpEmoW7cuevXqhejoaFStWvWF39PZ2Rlr167Fr7/+ioYNG2LDhg2YOXOmSfICD69w27hxIxo1aoQff/wRGzZsgK+vL4CH51EdPnwYVatWRZ8+feDj44Phw4cjLy+Pe4yISogg/vsgOREREZGF4R4iIiIisngsRERERGTxWIiIiIjI4rEQERERkcVjISIiIiKLx0JEREREFo+FiIiIiCweCxERERFZPBYiIiIisngsRERERGTxWIiIiIjI4rEQERERkcX7P0xtEOxj7vQFAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPSQWBEdsgRuQYebCfXl0n2",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}