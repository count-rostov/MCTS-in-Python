{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP020Bci5Eh6xTDCueqPGu6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emm32449/MCTS-in-Python/blob/main/MCTS_in_Python_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "help me code my version of alpha go zero for a small game:\n"
      ],
      "metadata": {
        "id": "wXX-0OzDrcwM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modifications for MCTS in Python 5:\n",
        "\n",
        "Simulation: Instead of simulating games to the end, we can use the neural network to evaluate the game state and estimate the value and policy. This can be done in the selection method of your MCTS class.\n",
        "\n",
        "Training: We can use the improved move probabilities from MCTS as targets to train the neural network. This can be done in the train method of your MCTS class."
      ],
      "metadata": {
        "id": "hT_Sd1Sunz5y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MCTS in Python 6:\n",
        "\n",
        "Your self_play function seems to be logically correct, but there are a few potential issues that might cause unexpected behavior:\n",
        "\n",
        "Random Simulation: In the line where you perform the simulation, you’re randomly choosing a child node for the simulation. This might not be ideal because it doesn’t take into account the potential value of each child node. Instead, you might want to use the policy predicted by your network to guide the simulation.\n",
        "\n",
        "Policy Calculation: You’re calculating the policy based on the visit counts of the children nodes. However, this policy is not being used anywhere in the MCTS process. Instead, you’re using a random action selection based on the visit counts. You might want to use this policy to guide the selection process in MCTS.\n",
        "\n",
        "Action Selection: You’re using torch.multinomial to select an action, which introduces randomness into the action selection process. This is generally a good approach for encouraging exploration during training, but you **might want to use a more deterministic action selection strategy during evaluation (e.g., choosing the action with the highest visit count or highest value).**\n",
        "\n",
        "Reward Calculation: You’re getting the reward from the final state after the game has ended. However, this reward is not being backpropagated up the tree. You might want to include a backpropagation step after the game ends to update the value estimates of the nodes.\n",
        "\n",
        "Root Initialization: You’re creating a new root node for each move. This means that the tree is discarded after each move, and the MCTS starts from scratch. This could be inefficient, especially if num_simulations is large. An alternative approach is to keep the subtree corresponding to the chosen action and use it as the new tree for the next move."
      ],
      "metadata": {
        "id": "ze5c4Gh97NOG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sPrMVo-gU3do"
      },
      "outputs": [],
      "source": [
        "# Assume we have a simple game state\n",
        "class GameState:\n",
        "    def __init__(self, state):\n",
        "        self.state = state\n",
        "\n",
        "    def __str__(self):\n",
        "        return str(self.state)\n",
        "\n",
        "    def get_legal_moves(self):\n",
        "        return [1, 2, 3]\n",
        "\n",
        "    def get_initial_state(self):\n",
        "        return GameState(0)\n",
        "\n",
        "    def make_move(self, move):\n",
        "        return GameState(self.state + move)\n",
        "\n",
        "    def is_terminal(self):\n",
        "        return self.state >= 10\n",
        "\n",
        "    def get_reward(self):\n",
        "        # Give a positive reward if the state is exactly 10\n",
        "        if self.state == 10:\n",
        "            return 1\n",
        "        # Give a negative reward if the state exceeds 10\n",
        "        elif self.state > 10:\n",
        "            return -1\n",
        "        # Give a reward based on how close the state is to 10\n",
        "        else:\n",
        "            return 1 - abs(self.state - 10) / 10\n",
        "\n",
        "    def reset(self):\n",
        "        self.state = 0\n",
        "\n",
        "    def copy(self):\n",
        "        return GameState(self.state)\n",
        "\n",
        "    def to_array(self):\n",
        "        return [self.state]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "import random\n",
        "\n",
        "class Node:\n",
        "    def __init__(self, game_state, policy, parent=None, move=None):\n",
        "        self.game_state = game_state\n",
        "        self.policy = policy\n",
        "        self.parent = parent\n",
        "        self.move = move\n",
        "        self.children = []\n",
        "        self.visits = 0\n",
        "        self.wins = 0\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"GameState: {self.game_state}, Move: {self.move}, Visits: {self.visits}, Wins: {self.wins}\"\n",
        "\n",
        "class MCTS:\n",
        "    def __init__(self, model, root):\n",
        "        self.model = model\n",
        "        self.root = root\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=0.001)\n",
        "\n",
        "    def choose_action(self, node):\n",
        "        # Choose the action that leads to the child with the most visits\n",
        "        max_visits = -math.inf\n",
        "        chosen_action = None\n",
        "        for child in node.children:\n",
        "            if child.visits > max_visits:\n",
        "                max_visits = child.visits\n",
        "                chosen_action = child.move\n",
        "        return chosen_action\n",
        "\n",
        "    def selection(self, node):\n",
        "        # While the current node has children (i.e., it's not a leaf node)\n",
        "        while len(node.children) > 0:\n",
        "            # Initialize the maximum value and the selected node\n",
        "            max_value = -math.inf\n",
        "            selected_node = None\n",
        "\n",
        "            # Loop over each child of the current node\n",
        "            for child in node.children:\n",
        "                # Convert the game state to a tensor\n",
        "                state_tensor = torch.tensor(node.game_state.to_array(), dtype=torch.float32)\n",
        "                # Use the neural network to evaluate the game state and estimate the policy and value\n",
        "                policy, value = self.model(state_tensor)\n",
        "\n",
        "                # Compute the Q-value (average reward) of the child node\n",
        "                Q = child.wins / child.visits if child.visits != 0 else 0\n",
        "                # Compute the U-value (exploration term) of the child node\n",
        "                U = policy.mean() * math.sqrt(node.visits) / (1 + child.visits)\n",
        "                # The value of the node is the sum of the Q-value and U-value\n",
        "                node_value = Q + U\n",
        "\n",
        "                # If the node's value is greater than the current maximum value\n",
        "                if node_value > max_value:\n",
        "                    # Update the maximum value and the selected node\n",
        "                    max_value = node_value\n",
        "                    selected_node = child\n",
        "\n",
        "            # Move to the selected node\n",
        "            node = selected_node\n",
        "\n",
        "        # Return the final selected node\n",
        "        return node\n",
        "\n",
        "    def expansion(self, node):\n",
        "        # Get the list of legal moves from the game state\n",
        "        legal_moves = node.game_state.get_legal_moves()\n",
        "\n",
        "        # For each legal move, create a new node and add it to the children of the current node\n",
        "        for move in legal_moves:\n",
        "            new_game_state = node.game_state.make_move(move)\n",
        "            state_tensor = torch.tensor(new_game_state.to_array(), dtype=torch.float32)\n",
        "            policy, value = self.model(state_tensor)\n",
        "            child_node = Node(new_game_state, policy, parent=node, move=move)\n",
        "            node.children.append(child_node)\n",
        "\n",
        "        return node.children\n",
        "\n",
        "    def simulation(self, node):\n",
        "        # Make a copy of the game state\n",
        "        game_state = node.game_state.copy()\n",
        "\n",
        "        # While the game is not over\n",
        "        while not game_state.is_terminal():\n",
        "\n",
        "            # Get the list of legal moves\n",
        "            legal_moves = game_state.get_legal_moves()\n",
        "\n",
        "            # Choose a move randomly\n",
        "            move = random.choice(legal_moves)\n",
        "\n",
        "            # Apply the move to get the next game state\n",
        "            game_state = game_state.make_move(move)\n",
        "\n",
        "        # Return the reward associated with the terminal state\n",
        "        return game_state.get_reward()\n",
        "\n",
        "    def backpropagation(self, node, reward):\n",
        "        # While node is not None\n",
        "        while node is not None:\n",
        "            # Update the visit count of the node\n",
        "            node.visits += 1\n",
        "\n",
        "            # Update the win count of the node\n",
        "            node.wins += reward\n",
        "\n",
        "            # Move to the parent node\n",
        "            node = node.parent\n",
        "\n",
        "    def run(self, simulations):\n",
        "        for _ in range(simulations):\n",
        "            # Start from the root node\n",
        "            node = self.root\n",
        "\n",
        "            # Selection\n",
        "            node = self.selection(node)\n",
        "\n",
        "            # Skip expansion, simulation, and backpropagation if a terminal node is selected\n",
        "            if node.game_state.is_terminal():\n",
        "                continue\n",
        "\n",
        "            # Expansion\n",
        "            if not node.game_state.is_terminal():\n",
        "                node = random.choice(self.expansion(node))\n",
        "\n",
        "            # Simulation\n",
        "            reward = self.simulation(node)\n",
        "\n",
        "            # Backpropagation\n",
        "            self.backpropagation(node, reward)\n",
        "\n",
        "            # Choose an action\n",
        "            chosen_action = self.choose_action(node)\n",
        "\n",
        "            # Get the list of children that match the chosen action\n",
        "            matching_children = [child for child in node.children if child.move == chosen_action]\n",
        "\n",
        "            # Check if there are any matching children\n",
        "            if matching_children:\n",
        "                # If there are, set the root to the first matching child\n",
        "                self.root = matching_children[0]\n",
        "            else:\n",
        "                # If there are no matching children, handle the error appropriately\n",
        "                print(\"No child found with the chosen action.\")\n",
        "\n",
        "    def print_tree(self, node, indent=\"\"):\n",
        "        print(indent + str(node))\n",
        "        for child in node.children:\n",
        "            self.print_tree(child, indent + \"  \")\n",
        "\n",
        "    def self_play(self, network, game, game_number, num_simulations=50):\n",
        "        states = []\n",
        "        policies = []\n",
        "        current_state = game.get_initial_state()\n",
        "\n",
        "        while not current_state.is_terminal():\n",
        "            # Initialize the root node with the current state\n",
        "            root = Node(current_state, None)\n",
        "\n",
        "            # Perform MCTS simulations from the root\n",
        "            for _ in range(num_simulations):\n",
        "                leaf = self.selection(root)\n",
        "                children = self.expansion(leaf)\n",
        "                reward = self.simulation(random.choice(children))\n",
        "                self.backpropagation(leaf, reward)\n",
        "\n",
        "            # Get the visit counts of the root's children\n",
        "            visit_counts = torch.tensor([child.visits for child in root.children]).float()\n",
        "\n",
        "            # Convert the visit counts to a policy\n",
        "            policy = F.softmax(visit_counts, dim=0).tolist()\n",
        "\n",
        "            # Choose an action based on the policy\n",
        "            action = root.children[torch.multinomial(visit_counts, 1).item()].move\n",
        "\n",
        "            # Store the numerical representation of the state and policy\n",
        "            states.append(current_state.to_array())\n",
        "            policies.append(policy)\n",
        "\n",
        "            # Apply the action to get the next state\n",
        "            current_state = current_state.make_move(action)\n",
        "\n",
        "        # Get the reward from the final state\n",
        "        reward = current_state.get_reward()\n",
        "\n",
        "        return states, policies, reward\n",
        "\n",
        "    # Use the improved move probabilities from MCTS as targets to train the neural network\n",
        "    # This function trains the neural network using the states, policies, and reward from self-play\n",
        "    def train(self, states, policies, reward, epochs):\n",
        "        # Convert the states, policies, and reward to PyTorch tensors\n",
        "        states = torch.tensor(states, dtype=torch.float32)\n",
        "        policies = torch.tensor(policies, dtype=torch.float32)\n",
        "        result = torch.tensor([reward] * len(states), dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "        # Loop over the number of training epochs\n",
        "        for _ in range(epochs):\n",
        "            # Get the predicted policy and value from the network\n",
        "            policy_pred, value_pred = self.model(states)\n",
        "\n",
        "            # Compute the policy loss as the KL divergence between the predicted and target policy\n",
        "            policy_loss = F.kl_div(F.log_softmax(policy_pred, dim=1), policies)\n",
        "            # Compute the value loss as the mean squared error between the predicted and actual reward\n",
        "            value_loss = F.mse_loss(value_pred, result)\n",
        "            # The total loss is the sum of the policy loss and value loss\n",
        "            loss = policy_loss + value_loss\n",
        "\n",
        "            # Zero the gradients, perform backpropagation, and update the network parameters\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "        # Return the final loss\n",
        "        return loss.item()"
      ],
      "metadata": {
        "id": "ZhvQXmsFU-tP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PolicyValueNet(nn.Module):\n",
        "    def __init__(self, num_actions):\n",
        "        super().__init__()\n",
        "        self.hidden1 = nn.Linear(1, 64)\n",
        "        self.hidden2 = nn.Linear(64, 64)\n",
        "\n",
        "        # Policy Head forms probabilites for each action, distribution\n",
        "        self.policy_head = nn.Linear(64, num_actions)\n",
        "\n",
        "        # Value Head predicts winner of game from each position, scaler\n",
        "        self.value_head = nn.Linear(64, 1)\n",
        "\n",
        "    def forward(self, state):\n",
        "        x = F.relu(self.hidden1(state))\n",
        "        x = F.relu(self.hidden2(x))\n",
        "        policy = F.softmax(self.policy_head(x), dim=-1)\n",
        "        value = torch.tanh(self.value_head(x))\n",
        "        return policy, value"
      ],
      "metadata": {
        "id": "kIZiFMNsVE0e"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initial Training Only"
      ],
      "metadata": {
        "id": "CU-XrgboolKM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the game and network\n",
        "game = GameState(0)\n",
        "num_actions = len(game.get_legal_moves())\n",
        "network = PolicyValueNet(num_actions)\n",
        "\n",
        "# Create a uniform policy\n",
        "uniform_policy = [1.0 / num_actions] * num_actions\n",
        "\n",
        "root = Node(game.get_initial_state(), uniform_policy)\n",
        "\n",
        "# Create the MCTS\n",
        "mcts = MCTS(network, root)\n",
        "\n",
        "# Initialize a list to store the losses\n",
        "losses = []\n",
        "\n",
        "# Set the model to training mode\n",
        "network.train()\n",
        "\n",
        "epochs = 50 # Play games\n",
        "game_number = 1\n",
        "\n",
        "# Generate self-play data and train the network\n",
        "for i in range(epochs):\n",
        "    states, actions, reward = mcts.self_play(network, game, game_number)\n",
        "    loss = mcts.train(states, actions, reward, epochs)\n",
        "    losses.append(loss)\n",
        "    game_number += 1"
      ],
      "metadata": {
        "id": "QoRvYDyWomfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save"
      ],
      "metadata": {
        "id": "Ye_YFclpayo7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Save the model, optimizer, game number, and losses\n",
        "torch.save({\n",
        "    'model_state_dict': network.state_dict(),\n",
        "    'optimizer_state_dict': mcts.optimizer.state_dict(),\n",
        "    'game_number': game_number,\n",
        "    'losses': losses\n",
        "}, '/content/drive/My Drive/MCTS in Python/MCTS_model.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBLAMk5XZrIt",
        "outputId": "79a90382-fe64-4981-eafe-cd56bf6039fd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load & Continue"
      ],
      "metadata": {
        "id": "ekdmEx-Pa1qo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create the game and network\n",
        "game = GameState(0)\n",
        "num_actions = len(game.get_legal_moves())\n",
        "network = PolicyValueNet(num_actions)\n",
        "\n",
        "# Load the model, optimizer, game number, and losses\n",
        "checkpoint = torch.load('/content/drive/My Drive/MCTS in Python/MCTS_model.pth')\n",
        "network.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "# Create a uniform policy\n",
        "uniform_policy = [1.0 / num_actions] * num_actions\n",
        "\n",
        "root = Node(game.get_initial_state(), uniform_policy)\n",
        "\n",
        "# Create the MCTS\n",
        "mcts = MCTS(network, root)\n",
        "mcts.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "game_number = checkpoint['game_number']\n",
        "losses = checkpoint['losses']\n",
        "\n",
        "# Set the model to training mode\n",
        "network.train()\n",
        "\n",
        "# Continue training for...<epochs> more games\n",
        "epochs=1000\n",
        "\n",
        "for _ in range(epochs):\n",
        "    states, actions, reward = mcts.self_play(network, game, game_number)\n",
        "    loss = mcts.train(states, actions, reward, epochs)\n",
        "    losses.append(loss)\n",
        "    game_number += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqpZ9ZDVatbC",
        "outputId": "90015d4c-8e23-4306-bea8-9d0268ec5173"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2943: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot"
      ],
      "metadata": {
        "id": "qVkffWvpo4t9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Print and plot the losses\n",
        "print(f\"Average Loss: {sum(losses) / len(losses)}, Max Loss: {max(losses)}, Min Loss: {min(losses)}\")\n",
        "plt.plot(losses)\n",
        "plt.xlabel('Game')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss per Game')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HtdY1Rp_ox9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "outputId": "7a9d2089-19a5-459e-c57c-779dad37953d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Loss: 0.24662748484313488, Max Loss: 3.7292094230651855, Min Loss: 0.06270544230937958\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABgrklEQVR4nO3dd3gUVcM28HsTUiHZ0NIgQCAQeoAAIXQkEIoIooKoD0VEEVB8UFFQQUENykt7pH8KKIg0BZReQw09oUroJEAKAdJJ3fP9ETLZSXbT2GQ3s/fPay/Z2TOzZ7K7M/ecc2ZGJYQQICIiIlIIC2NXgIiIiMiQGG6IiIhIURhuiIiISFEYboiIiEhRGG6IiIhIURhuiIiISFEYboiIiEhRGG6IiIhIURhuiIiISFEYboiIiEhRGG6IFGzVqlVQqVQ4c+aMsatSYRw5cgRDhgxBrVq1YG1tDbVaDT8/P8yYMQMxMTHGrh4RFUMlY1eAiMhUTJs2DTNnzkT9+vUxcuRI1K9fH2lpaTh79izmzJmDX3/9FTdv3jR2NYmoCAw3RGQWhBBIS0uDnZ2dztfXr1+PmTNnYsiQIVi9ejWsra1lr8+bNw/z5s0rj6oS0XNitxQRITQ0FH379oWjoyOqVKmCnj174sSJE7IymZmZ+Oabb9CwYUPY2tqievXq6Ny5M/bu3SuViY6OxqhRo1C7dm3Y2NjAzc0NAwcOxJ07dwp9/5EjR6JKlSq4desWAgMDUblyZbi7u2PGjBkQQsjKajQazJ8/H82aNYOtrS1cXFzw3nvv4cmTJ7Jy9erVw4svvojdu3ejbdu2sLOzw7Jly/TWYdq0aahRowZ++eWXAsEGANRqNb7++mvZtK1bt6J///5wd3eHjY0NGjRogJkzZyI7O1tWrnv37mjevDkuXLiAbt26wd7eHl5eXti0aRMA4NChQ/Dz84OdnR28vb2xb9++Au9///59vP3223BxcYGNjQ2aNWuGFStWFPp3JTJXDDdEZu7y5cvo0qULzp8/j8mTJ+Orr77C7du30b17d5w8eVIq9/XXX+Obb75Bjx49sHDhQnzxxReoU6cOzp07J5V55ZVXsHnzZowaNQqLFy/Ghx9+iKSkJERERBRZj+zsbPTp0wcuLi748ccf4evri+nTp2P69Omycu+99x4+/fRTdOrUCQsWLMCoUaPw+++/IzAwEJmZmbKy4eHhGDZsGHr16oUFCxagVatWOt/72rVruHbtGgYNGoQqVaoU+2+3atUqVKlSBZMmTcKCBQvg6+uLadOm4fPPPy9Q9smTJ3jxxRfh5+eHH3/8ETY2Nnj99dexfv16vP766+jXrx9mzZqFlJQUvPrqq0hKSpLmjYmJQYcOHbBv3z5MmDABCxYsgJeXF0aPHo358+cXu75EZkMQkWKtXLlSABCnT5/WW2bQoEHC2tpa3Lx5U5r24MED4eDgILp27SpN8/HxEf3799e7nCdPnggAYvbs2SWu54gRIwQA8cEHH0jTNBqN6N+/v7C2thYPHz4UQghx5MgRAUD8/vvvsvl37dpVYHrdunUFALFr164i33/r1q0CgJg/f75sukajEQ8fPpQ9MjMzpddTU1MLLOu9994T9vb2Ii0tTZrWrVs3AUCsXbtWmnb16lUBQFhYWIgTJ05I03fv3i0AiJUrV0rTRo8eLdzc3ERcXJzsvV5//XWhVqt11oPInLHlhsiMZWdnY8+ePRg0aBDq168vTXdzc8Mbb7yBo0ePIjExEQDg5OSEy5cv4/r16zqXZWdnB2trawQHBxfoIiquCRMmSP9WqVSYMGECMjIypG6ajRs3Qq1Wo1evXoiLi5Mevr6+qFKlCg4ePChbnqenJwIDA4t839x1zN9qk5CQgJo1a8oeYWFhsnXOlZSUhLi4OHTp0gWpqam4evWqbFlVqlTB66+/Lj339vaGk5MTmjRpAj8/P2l67r9v3boFIGes0J9//okBAwZACCFb78DAQCQkJMhaz4iI3VJEZu3hw4dITU2Ft7d3gdeaNGkCjUaDyMhIAMCMGTMQHx+PRo0aoUWLFvj0009x4cIFqbyNjQ1++OEH7Ny5Ey4uLujatSt+/PFHREdHF6suFhYWsoAFAI0aNQIAaczO9evXkZCQAGdn5wKhIzk5GbGxsbL5PT09i/XeDg4OAIDk5GTZ9CpVqmDv3r3Yu3cvPv300wLzXb58GS+//DLUajUcHR1Rs2ZNvPXWWwBygpG22rVrQ6VSyaap1Wp4eHgUmAZACogPHz5EfHw8li9fXmCdR40aBQAF1pvI3PFsKSIqlq5du+LmzZvYunUr9uzZg59//hnz5s3D0qVL8c477wAAPvroIwwYMABbtmzB7t278dVXXyEoKAgHDhxA69atn7sOGo0Gzs7O+P3333W+XrNmTdlzfWdG5de4cWMAwKVLl2TTK1WqhICAAADAvXv3ZK/Fx8ejW7ducHR0xIwZM9CgQQPY2tri3Llz+Oyzz6DRaGTlLS0tdb63vuni2UDq3OW89dZbGDFihM6yLVu2LGz1iMwOww2RGatZsybs7e0RHh5e4LWrV6/CwsJC1rJQrVo1jBo1CqNGjUJycjK6du2Kr7/+Wgo3ANCgQQN8/PHH+Pjjj3H9+nW0atUKc+bMwZo1awqti0ajwa1bt6TWGiBnoC+Qc+ZT7rL37duHTp06FTu4FIe3tzcaNmyILVu2YP78+ahcuXKR8wQHB+PRo0f466+/0LVrV2n67du3DVYvIOczcnBwQHZ2thS0iKhw7JYiMmOWlpbo3bs3tm7dKjtdOyYmBmvXrkXnzp3h6OgIAHj06JFs3ipVqsDLywvp6ekAgNTUVKSlpcnKNGjQAA4ODlKZoixcuFD6txACCxcuhJWVFXr27AkAGDJkCLKzszFz5swC82ZlZSE+Pr5Y76PL119/jbi4OIwZM6bAWVe59dGW2+KiPT0jIwOLFy8udR10sbS0xCuvvII///yzQMsSkNNtRURybLkhMgMrVqzArl27CkyfOHEivv32W+zduxedO3fGuHHjUKlSJSxbtgzp6en48ccfpbJNmzZF9+7d4evri2rVquHMmTPYtGmTNAj42rVr6NmzJ4YMGYKmTZuiUqVK2Lx5M2JiYmQDafWxtbXFrl27MGLECPj5+WHnzp3Yvn07pk6dKnU3devWDe+99x6CgoIQFhaG3r17w8rKCtevX8fGjRuxYMECvPrqq6X6G73xxhu4dOkSgoKCcOrUKbz++uvw9PRESkoKLl26hD/++AMODg6oWrUqAKBjx46oWrUqRowYgQ8//BAqlQqrV68uEIIMYdasWTh48CD8/PwwZswYNG3aFI8fP8a5c+ewb98+PH782ODvSVShGfFMLSIqY7mngut7REZGCiGEOHfunAgMDBRVqlQR9vb2okePHuL48eOyZX377beiffv2wsnJSdjZ2YnGjRuL7777TmRkZAghhIiLixPjx48XjRs3FpUrVxZqtVr4+fmJDRs2FFnPESNGiMqVK4ubN2+K3r17C3t7e+Hi4iKmT58usrOzC5Rfvny58PX1FXZ2dsLBwUG0aNFCTJ48WTx48EAqU7du3UJPXdcnODhYvPrqq8LNzU1YWVkJR0dH0bZtWzF9+nQRFRUlK3vs2DHRoUMHYWdnJ9zd3cXkyZOlU7kPHjwolevWrZto1qxZgffSV0cAYvz48bJpMTExYvz48cLDw0NYWVkJV1dX0bNnT7F8+fISryOR0qmEKIPDDCKiEhg5ciQ2bdpU4GwlIqLS4JgbIiIiUhSGGyIiIlIUhhsiIiJSFI65ISIiIkVhyw0REREpCsMNERERKYrZXcRPo9HgwYMHcHBwKHATOyIiIjJNQggkJSXB3d0dFhaFt82YXbh58OBBgbvwEhERUcUQGRmJ2rVrF1rG7MKNg4MDgJw/Tu49c4iIiMi0JSYmwsPDQ9qPF8bswk1uV5SjoyPDDRERUQVTnCElHFBMREREisJwQ0RERIrCcENERESKwnBDREREisJwQ0RERIrCcENERESKwnBDREREisJwQ0RERIrCcENERESKwnBDREREisJwQ0RERIrCcENERESKwnBTBp5mZBu7CkRERGaL4cbAftp/HU2m7cLBq7HGrgoREZFZYrgxsDl7rwEApm6+aOSaEBERmSeGGyIiIlIUhhsiIiJSFIYbIiIiUhSGGyIiIlIUhhsiIiJSFIYbIiIiUhSGGyIiIlIUhhsiIiJSFIYbIiIiUhSGGyIiIlIUhhsiIiJSFIYbIiIiUhSGGyIiIlIUhhsiIiJSFIYbIiIiUhSGGyIiIlIUo4abJUuWoGXLlnB0dISjoyP8/f2xc+dOveVXrVoFlUole9ja2pZjjYmIiMjUVTLmm9euXRuzZs1Cw4YNIYTAr7/+ioEDByI0NBTNmjXTOY+joyPCw8Ol5yqVqryqS0RERBWAUcPNgAEDZM+/++47LFmyBCdOnNAbblQqFVxdXcujekRERFQBmcyYm+zsbKxbtw4pKSnw9/fXWy45ORl169aFh4cHBg4ciMuXLxe63PT0dCQmJsoeREREpFxGDzcXL15ElSpVYGNjg7Fjx2Lz5s1o2rSpzrLe3t5YsWIFtm7dijVr1kCj0aBjx464d++e3uUHBQVBrVZLDw8Pj7JaFSIiIjIBKiGEMGYFMjIyEBERgYSEBGzatAk///wzDh06pDfgaMvMzESTJk0wbNgwzJw5U2eZ9PR0pKenS88TExPh4eGBhIQEODo6Gmw9ctX7fDsAwE1ti5ApPQ2+fCIiInOUmJgItVpdrP23UcfcAIC1tTW8vLwAAL6+vjh9+jQWLFiAZcuWFTmvlZUVWrdujRs3bugtY2NjAxsbG4PVl4iIiEyb0bul8tNoNLKWlsJkZ2fj4sWLcHNzK+NaERERUUVh1JabKVOmoG/fvqhTpw6SkpKwdu1aBAcHY/fu3QCA4cOHo1atWggKCgIAzJgxAx06dICXlxfi4+Mxe/Zs3L17F++8844xV4OIiIhMiFHDTWxsLIYPH46oqCio1Wq0bNkSu3fvRq9evQAAERERsLDIa1x68uQJxowZg+joaFStWhW+vr44fvx4scbnEBERkXkw+oDi8laSAUmlwQHFREREhleS/bfJjbkhIiIieh4MN0RERKQoDDdERESkKAw3REREpCgMN0RERKQoDDdERESkKAw3REREpCgMN0RERKQoDDdERESkKAw3REREpCgMN0RERKQoDDdERESkKAw3REREpCgMN0RERKQoDDdERESkKAw3REREpCgMN0RERKQoDDdERESkKAw3REREpCgMN0RERKQoDDdERESkKAw3REREpCgMN0RERKQoDDdERESkKAw3REREpCgMN0RERKQoDDdERESkKAw3REREpCgMN0RERKQoDDdERESkKAw3REREpCgMN0RERKQoDDdERESkKAw3REREpChGDTdLlixBy5Yt4ejoCEdHR/j7+2Pnzp2FzrNx40Y0btwYtra2aNGiBXbs2FFOtSUiIqKKwKjhpnbt2pg1axbOnj2LM2fO4IUXXsDAgQNx+fJlneWPHz+OYcOGYfTo0QgNDcWgQYMwaNAgXLp0qZxrTkRERKZKJYQQxq6EtmrVqmH27NkYPXp0gdeGDh2KlJQUbNu2TZrWoUMHtGrVCkuXLi3W8hMTE6FWq5GQkABHR0eD1TtXvc+3AwDc1LYImdLT4MsnIiIyRyXZf5vMmJvs7GysW7cOKSkp8Pf311kmJCQEAQEBsmmBgYEICQkpjyoSERFRBVDJ2BW4ePEi/P39kZaWhipVqmDz5s1o2rSpzrLR0dFwcXGRTXNxcUF0dLTe5aenpyM9PV16npiYaJiKExERkUkyesuNt7c3wsLCcPLkSbz//vsYMWIErly5YrDlBwUFQa1WSw8PDw+DLZuIiIhMj9HDjbW1Nby8vODr64ugoCD4+PhgwYIFOsu6uroiJiZGNi0mJgaurq56lz9lyhQkJCRIj8jISIPWn4iIiEyL0cNNfhqNRtaNpM3f3x/79++XTdu7d6/eMToAYGNjI51qnvsgIiIi5TLqmJspU6agb9++qFOnDpKSkrB27VoEBwdj9+7dAIDhw4ejVq1aCAoKAgBMnDgR3bp1w5w5c9C/f3+sW7cOZ86cwfLly425GkRERGRCjBpuYmNjMXz4cERFRUGtVqNly5bYvXs3evXqBQCIiIiAhUVe41LHjh2xdu1afPnll5g6dSoaNmyILVu2oHnz5sZaBSIiIjIxJnedm7LG69wQERFVPBXyOjdEREREhsBwQ0RERIrCcENERESKwnBDREREisJwQ0RERIrCcENERESKwnBDREREisJwQ0RERIrCcENERESKwnBDREREisJwQ0RERIrCcENERESKwnBDREREisJwQ0RERIrCcENERESKwnBDREREisJwQ0RERIrCcENERESKwnBDREREisJwQ0RERIrCcENERESKwnBDREREisJwQ0RERIrCcENERESKwnBDREREisJwQ0RERIrCcENERESKwnBDREREisJwQ0RERIrCcENERESKwnBDREREisJwQ0RERIrCcFNGVMauABERkZliuCkjwtgVICIiMlMMN0RERKQoRg03QUFBaNeuHRwcHODs7IxBgwYhPDy80HlWrVoFlUole9ja2pZTjYmIiMjUGTXcHDp0COPHj8eJEyewd+9eZGZmonfv3khJSSl0PkdHR0RFRUmPu3fvllONiYiIyNRVMuab79q1S/Z81apVcHZ2xtmzZ9G1a1e986lUKri6upZ19YiIiKgCMqkxNwkJCQCAatWqFVouOTkZdevWhYeHBwYOHIjLly+XR/WIiIioAjCZcKPRaPDRRx+hU6dOaN68ud5y3t7eWLFiBbZu3Yo1a9ZAo9GgY8eOuHfvns7y6enpSExMlD2IiIhIuYzaLaVt/PjxuHTpEo4ePVpoOX9/f/j7+0vPO3bsiCZNmmDZsmWYOXNmgfJBQUH45ptvDF5fIiIiMk0m0XIzYcIEbNu2DQcPHkTt2rVLNK+VlRVat26NGzdu6Hx9ypQpSEhIkB6RkZGGqDIRERGZKKO23Agh8MEHH2Dz5s0IDg6Gp6dniZeRnZ2Nixcvol+/fjpft7GxgY2NzfNWlYiIiCoIo4ab8ePHY+3atdi6dSscHBwQHR0NAFCr1bCzswMADB8+HLVq1UJQUBAAYMaMGejQoQO8vLwQHx+P2bNn4+7du3jnnXeMth668PYLRERExmHUcLNkyRIAQPfu3WXTV65ciZEjRwIAIiIiYGGR13v25MkTjBkzBtHR0ahatSp8fX1x/PhxNG3atLyqXSy8/QIREZFxqIQQZrUfTkxMhFqtRkJCAhwdHQ2+/HqfbwcAuKltETKlp8GXT0REZI5Ksv82iQHFRERERIbCcENERESKwnBDREREisJwQ0RERIrCcENERESKwnBDREREisJwQ0RERIrCcENERESKwnBTRnj7BSIiIuNguCkjZnXZZyIiIhPCcENERESKwnBDREREisJwQ0RERIrCcENERESKwnBDREREisJwQ0RERIrCcENERESKwnBDREREisJwQ0RERIrCcFNGePsFIiIi42C4KSO8/QIREZFxMNwQERGRojDcEBERkaIw3BAREZGiMNwQERGRojDclBGeLUVERGQcDDdlhGdLERERGQfDDRERESkKww0REREpCsMNERERKQrDTRnhgGIiIiLjYLgpIxxQTEREZBwMN0RERKQoDDdERESkKAw3REREpChGDTdBQUFo164dHBwc4OzsjEGDBiE8PLzI+TZu3IjGjRvD1tYWLVq0wI4dO8qhtkRERFQRGDXcHDp0COPHj8eJEyewd+9eZGZmonfv3khJSdE7z/HjxzFs2DCMHj0aoaGhGDRoEAYNGoRLly6VY82LxrOliIiIjEMlhCjxiT2RkZFQqVSoXbs2AODUqVNYu3YtmjZtinfffbfUlXn48CGcnZ1x6NAhdO3aVWeZoUOHIiUlBdu2bZOmdejQAa1atcLSpUuLfI/ExESo1WokJCTA0dGx1HXVp97n2wEAbmpbhEzpafDlExERmaOS7L9L1XLzxhtv4ODBgwCA6Oho9OrVC6dOncIXX3yBGTNmlGaRAICEhAQAQLVq1fSWCQkJQUBAgGxaYGAgQkJCdJZPT09HYmKi7EFERETKVapwc+nSJbRv3x4AsGHDBjRv3hzHjx/H77//jlWrVpWqIhqNBh999BE6deqE5s2b6y0XHR0NFxcX2TQXFxdER0frLB8UFAS1Wi09PDw8SlU/IiIiqhhKFW4yMzNhY2MDANi3bx9eeuklAEDjxo0RFRVVqoqMHz8ely5dwrp160o1vz5TpkxBQkKC9IiMjDTo8omIiMi0lCrcNGvWDEuXLsWRI0ewd+9e9OnTBwDw4MEDVK9evcTLmzBhArZt24aDBw9K43j0cXV1RUxMjGxaTEwMXF1ddZa3sbGBo6Oj7FEeOKCYiIjIOEoVbn744QcsW7YM3bt3x7Bhw+Dj4wMA+Pvvv6XuquIQQmDChAnYvHkzDhw4AE9PzyLn8ff3x/79+2XT9u7dC39//5KtRBnj7ReIiIiMo1JpZurevTvi4uKQmJiIqlWrStPfffdd2NvbF3s548ePx9q1a7F161Y4ODhI42bUajXs7OwAAMOHD0etWrUQFBQEAJg4cSK6deuGOXPmoH///li3bh3OnDmD5cuXl2ZViIiISGFK1XLz9OlTpKenS8Hm7t27mD9/PsLDw+Hs7Fzs5SxZsgQJCQno3r073NzcpMf69eulMhEREbJxPB07dsTatWuxfPly+Pj4YNOmTdiyZUuhg5DNxT/nH+DivQRjV4OIiMioStVyM3DgQAwePBhjx45FfHw8/Pz8YGVlhbi4OMydOxfvv/9+sZZTnEvsBAcHF5j22muv4bXXXitptY1KCIHz9xJQv2ZlONpaGXz55yKe4IM/QgEAd2b1N/jyiYiIKopStdycO3cOXbp0AQBs2rQJLi4uuHv3Ln777Tf873//M2gFlWL35RgMWnQM/RYcKZPl34hNLpPlEhERVTSlCjepqalwcHAAAOzZsweDBw+GhYUFOnTogLt37xq0ghVV/rOltl/M6Vq79+Rp+VeGiIjIjJQq3Hh5eWHLli2IjIzE7t270bt3bwBAbGxsuZ1qbep4thQREZFxlCrcTJs2DZ988gnq1auH9u3bS6dh79mzB61btzZoBYmIiIhKolQDil999VV07twZUVFR0jVuAKBnz554+eWXDVY5Kj5eNJCIiChHqcINkHOlYFdXV9y7dw8AULt27RJdwI8Mi91gREREOUrVLaXRaDBjxgyo1WrUrVsXdevWhZOTE2bOnAmNRmPoOlZIbEkhIiIyjlK13HzxxRf45ZdfMGvWLHTq1AkAcPToUXz99ddIS0vDd999Z9BKEhERERVXqcLNr7/+ip9//lm6GzgAtGzZErVq1cK4ceMYbsBuIiIiImMpVbfU48eP0bhx4wLTGzdujMePHz93pajk2A1GRESUo1ThxsfHBwsXLiwwfeHChWjZsuVzV4qIiIiotErVLfXjjz+if//+2Ldvn3SNm5CQEERGRmLHjh0GrSCVXFxyOmpUsTF2NYiIiIyiVC033bp1w7Vr1/Dyyy8jPj4e8fHxGDx4MC5fvozVq1cbuo4VkjG7iTr/cMCI705ERGRcpb7Ojbu7e4GBw+fPn8cvv/yC5cuXP3fFKjpjDihOy+Tp+EREZL5K1XJDREREZKoYboiIiEhRGG6IiIhIUUo05mbw4MGFvh4fH/88dVEUXneGiIjIOEoUbtRqdZGvDx8+/LkqRERERPQ8ShRuVq5cWVb1UBzefoGIiMg4OOZGIVQqdoQREREBDDdERESkMAw35eDS/QT8c/6BsatBRERkFhhuyoh2J9F7q88arR5ERETmhuGmjGgPKE7PyjZaPYiIiMwNww0REREpCsMNERERKQrDDRERESkKw00Z4VVniIiIjIPhplyUfdRhmCIiIsrBcFNGePsFIiIi42C4ISIiIkVhuCEiIiJFYbghIiIiRWG4KSPaA3x5w24iIqLyY9Rwc/jwYQwYMADu7u5QqVTYsmVLoeWDg4OhUqkKPKKjo8unwkRERGTyjBpuUlJS4OPjg0WLFpVovvDwcERFRUkPZ2fnMqph6fFsKSIiIuOoZMw379u3L/r27Vvi+ZydneHk5GT4ChEREVGFVyHH3LRq1Qpubm7o1asXjh07VmjZ9PR0JCYmyh5ERESkXBUq3Li5uWHp0qX4888/8eeff8LDwwPdu3fHuXPn9M4TFBQEtVotPTw8PMqlrsYeQ7w65A7Ss7KNXAsiIqLyZ9RuqZLy9vaGt7e39Lxjx464efMm5s2bh9WrV+ucZ8qUKZg0aZL0PDExsdwCTnnKf0bWV1sv42FyBib1amScChERERlJhQo3urRv3x5Hjx7V+7qNjQ1sbGzKsUY5TGFA8Ymbj4Bexq4FERFR+apQ3VK6hIWFwc3NzdjVMEnZwhQiFhERUfkyastNcnIybty4IT2/ffs2wsLCUK1aNdSpUwdTpkzB/fv38dtvvwEA5s+fD09PTzRr1gxpaWn4+eefceDAAezZs8dYq2DSsjUMN0REZH6MGm7OnDmDHj16SM9zx8aMGDECq1atQlRUFCIiIqTXMzIy8PHHH+P+/fuwt7dHy5YtsW/fPtkyTJGxBhcLttwQEZEZMmq46d69e6E74FWrVsmeT548GZMnTy7jWhmGsc+WAtgtRURE5qnCj7kh/bI1xq4BERFR+WO4KSO5bSaxiWnIMtLYFw3H3BARkRliuClD4dFJaP/9fjxOyTD4so/diMOEtefwKDldbxl2SxERkTmq8Ne5MVVRCWkInH+4zJb/5s8nAQCWFioseL21zjJsuSEiInPElpsK7kH8U72vadhyQ0REZojhRiHy334BYLcUERGZJ4YbBdPwbCkiIjJDDDcKxisUExGROWK4UTB2SxERkTliuFEw3n6BiIjMEcONgsUlZzDgEBGR2WG4UbjJmy4YuwpERETliuFG4TaevWfsKhAREZUrhhsjSMvMZncRERFRGWG4MYLGX+3CpA3njV0NIiIiRWK4MZLNofeNXQUiIiJFYrhRCBV03H+BiIjIDDHcEBERkaIw3BAREZGiMNwQERGRojDcVHAca0NERCRXydgVoJIRQuDErcd5z8Hr5RAREWljy00Fc+jaQwz7fyeMXQ0iIiKTxXBTwRy+FmfsKhAREZk0hpsKRsUhNkRERIViuKngTt95grDIeGNXg4iIyGQw3CjAoEXH9L7Wtm7VcqwJERGR8THcKAS7q4iIiHIw3BAREZGiMNwoHK+CQ0RE5obhpgLJyNLg4v0EY1eDiIjIpDHcVCAT1p7DqduPiy6oRQi23RARkXlhuKlA9lyJ0fvanD3XdE5ntCEiInPDcKMQEY9TjV0FIiIik8Bwo1AujjYAAPZKERGRuTFquDl8+DAGDBgAd3d3qFQqbNmypch5goOD0aZNG9jY2MDLywurVq0q83qagvMlvAqxl3OVsqkIERGRiTNquElJSYGPjw8WLVpUrPK3b99G//790aNHD4SFheGjjz7CO++8g927d5dxTY1v9Ym7JSqvQs5V/dhwQ0RE5qaSMd+8b9++6Nu3b7HLL126FJ6enpgzZw4AoEmTJjh69CjmzZuHwMDAsqqmSSjpBYh5xWIiIjJXFWrMTUhICAICAmTTAgMDERISonee9PR0JCYmyh7mQJWbbjjohoiIzEyFCjfR0dFwcXGRTXNxcUFiYiKePn2qc56goCCo1Wrp4eHhUR5VNTo23BARkbmqUOGmNKZMmYKEhATpERkZaewqlUhSWmap5rPIbbgxYF2IiIgqAqOOuSkpV1dXxMTIL2QXExMDR0dH2NnZ6ZzHxsYGNjY25VE9g/vn/AN88EcoJvZsiI1n75Vo3txuKfZKERGRualQLTf+/v7Yv3+/bNrevXvh7+9vpBqVrS82XwQALNh/vcTzsluKiIjMlVHDTXJyMsLCwhAWFgYg51TvsLAwREREAMjpUho+fLhUfuzYsbh16xYmT56Mq1evYvHixdiwYQP++9//GqP6Jk0aT8yOKSIiMjNGDTdnzpxB69at0bp1awDApEmT0Lp1a0ybNg0AEBUVJQUdAPD09MT27duxd+9e+Pj4YM6cOfj5558Vfxp4aah4LjgREZkpo4656d69e6F3rdZ19eHu3bsjNDS0DGtlGrI1AolpWaWePzfacMwNERGZmwo15sacrA6581zzs+GGiIjMFcONidpzJaboQoWw4NlSRERkphhuFErF69wQEZGZYrgxUc/brcQBxUREZK4YbhQqb0Ax226IiMi8MNyYKNVzXoaPLTdERGSuGG4UitGGiIjMFcONEZVll5EF0w0REZkphhsjKsvhMLxxJhERmSuGGyPS6EkeaZnZSErLfK5lSwOKeTI4ERGZGaPefsHc6Ysd/kH78ST1OcMNBxQTEZGZYsuNEelruXneYANoXcSPDTdERGRmGG6MqEzH3JTdoomIiEwaw40Rle2A4mfvUXZvQUREZJIYboyoLAf7WnDMDRERmSmGGyMql5YbDrohIiIzw3BjRPoGFBuCdJ2bMnsHIiIi08RwY0RlGTzYKUVEROaK4caIhKbslq3Ku4ofERGRWWG4MSIOKCYiIjI8hhsj0pTDdW7YcENEROaG4caIdJ3JZKizm3j7BSIiMlcMN0akK8YY+gQqngpORETmhuHGiHSdCm6oKMIrFBMRkbliuDGmZ8nj5sNkXI1OzJlkqG4pngxORERmqpKxK2DONALQaAR6zjkEALjwdW/YVrI0yLJ5V3AiIjJXbLkxIgGBbK30EZeUbrDTw9luQ0RE5orhxojynwquEWUwoJijboiIyMww3BiRECLfoGLDBRGeCU5EROaK4caIRL6WGkO23Eg3zmTDDRERmRmGGyMqGG7yt+SUHhtuiIjIXDHcGJF49p/0XBj+ujRsuSEiInPDcGNE+buhNELwisJERETPieHGiPIPKDZkyw0jEhERmSuGGyPS5AszCU8z8fqyE4ZZ9rPzzNkSRERE5sYkws2iRYtQr1492Nraws/PD6dOndJbdtWqVVCpVLKHra1tOdbWkASEJu/ZTweu40pUooGWTEREZJ6MHm7Wr1+PSZMmYfr06Th37hx8fHwQGBiI2NhYvfM4OjoiKipKety9e7cca2w47/52VnaF4sSnWQZbdm53F0MOERGZG6OHm7lz52LMmDEYNWoUmjZtiqVLl8Le3h4rVqzQO49KpYKrq6v0cHFxKccaG86tuBQcvxknPTdkEGFvFBERmSujhpuMjAycPXsWAQEB0jQLCwsEBAQgJCRE73zJycmoW7cuPDw8MHDgQFy+fFlv2fT0dCQmJsoepiQtM69fypDjY6SWG4YcIiIyM0YNN3FxccjOzi7Q8uLi4oLo6Gid83h7e2PFihXYunUr1qxZA41Gg44dO+LevXs6ywcFBUGtVksPDw8Pg6/H8xD5zpYylLxuKaYbIiIyL0bvliopf39/DB8+HK1atUK3bt3w119/oWbNmli2bJnO8lOmTEFCQoL0iIyMLOcaFy7/dW4MJf9NOYmIiMxFJWO+eY0aNWBpaYmYmBjZ9JiYGLi6uhZrGVZWVmjdujVu3Lih83UbGxvY2Ng8d13LinagMWS4EeyWIiIiM2XUlhtra2v4+vpi//790jSNRoP9+/fD39+/WMvIzs7GxYsX4ebmVlbVLFMaofvfz4uhhoiIzJVRW24AYNKkSRgxYgTatm2L9u3bY/78+UhJScGoUaMAAMOHD0etWrUQFBQEAJgxYwY6dOgALy8vxMfHY/bs2bh79y7eeecdY65GqWmPiTFstxRPBSciIvNk9HAzdOhQPHz4ENOmTUN0dDRatWqFXbt2SYOMIyIiYGGR18D05MkTjBkzBtHR0ahatSp8fX1x/PhxNG3a1Fir8Fw0Ws012QZsuuGYGyIiMldGDzcAMGHCBEyYMEHna8HBwbLn8+bNw7x588qhVuVDO4SUydlSJhZyhBBQqVTGrgYRESlYhTtbSmlEmQ0olv5lsGU+rx92XUXHWQcQl5xu7KoQEZGCMdwYmabMTgU3nVCTa0nwTUQlpOH/Hb5l7KqUCyEEZu28it9PVpzbg/BGq0SkBAw3RiY/FdyQy835vynuq0ywSmXiwr0ELD10E19svmTsqhTLjotRaP/9fpy+89jYVVG8G7HJOHHrkbGrQaRYDDdGJruIn0EHFJtLhDBdyemGuxFqeRj3+zk8TErHyBWnjF0VxQuYewivLz+Bmw+TjV0VIkViuDGysjoV3Ke2+tnyTY+5dH1U1GHT6VmaoguRQVyLTjJ2FYgUieHGyLI12v823E6/u7ez7PnakxGYt/ea3vKbQ+9h16WoYi07NimtQEA5fecxlh66WaD1aWvYfVy4F48nKRnFrLlp02gEpm29hI1nir6Nh/ZZYaYe6P45/0D6d7aJ11XJhBB4mpFd7u8Zn6qM32dhYhILbreKQ6MRuBGbZPK/YZJjuDGyiMep0r8T0wzTjVGnmr3UapD7g5y6+SIW7L+O6zEFjxQfJqXjv+vPY+yacwUC1oYzkXh1yXE8enaG08YzkWj/3X78uDtcVu61pSGYtfMq6k/dgUUHc26FcfrOY0xcF4aXFh7DkGV5d3mvyKeCH7gai99C7uLTTReKLGuhtZpZ5XjhoeDwWPScE4xzEU+KPc8Hf4RK/+Y23HjGrjmLJtN24d6TVDyIf4q1JyOQlmn4sLPxTCQ6zTqAf6MS8fmfF9Fqxl5Fj7XaGnYfft/vx7fb/wUAPC7BwdYPu64iYO7hQg8OS2LNibvoNOsAuyTLGMONkf1xKsLgy9Tu3sq/n0rSMQ4kMS1T+neWRt4lMXnTBZy5+wRzn/2wp/99GUDOmU/rT0foPPNp9rPgcyM278d7PVYZP+SEp5lFF3rGQivdZGWXX2IYufI0bj5MwfBfzHvszD/nHyC0BAHPFOy+nHOfvQ2nIzHgp6OYuvmiwXaq2j7ddAH3459i8qYLWP+sFXL+PsO/j6n4eMN5AMAvR29j/ekItJm5VzoIK8qyZ9u4/x0oXvmifLnlEu7HP8X0rZcNsjzSjeHGgMriCKs0rCtZQLtxRLurqKg2E+2WG+2uityduvb8n/15Ed/t+Bd3H6WUqH6m2Ly761I0Jq0PK7JLwNKi+K1O8pYbw4xjWR1yByNWnCpW10Vyehb+jUrEjH+u4ElKBoQQ+OvcPdyIlbfelaY79NL9BCwJvonMbNMcn3PpfgI++CMULy8+jrN3cwJOXHI6vth8EZfuJ0jljt2IQ3gh416eZmTj/3aH48K9+CLf82FSuvTd3n05GjsvFq+bNzUjC5M3ncfB8FhpWrYQePSsdSE4/GGxllMc8akZsp269jYrJT3n39dikjBnT7jsoCdXZrYGkzaEYdPZe6Wuw+OUDMQkppV6/qIkPM3Et9uuyD5n7ZbTz/68CCDvIEyXqISnuBqdWKz3i01Kk70XkNPi/e22K4Vu60q7TYhKeFrgNyuEwLEbcWX6d61oGG4M6E4Jd/KGMMK/boFp9taW0r+FkI+hKKpL6NTtxxBCIOJRqqyrYtuFKKRm6O42e5JacCMY8ShV1nKjixACoRFPkKBj/vyKszPPytboPUNJCIErDxL17ozHrjmLv0LvY+mhmwByWrNO33lcYOOk3RrTffbBIsYq5JUtSYD43/7rCJx3WGcr0VdbL+PQtYfFbvHru+AIVhy7jWl/X8aOi9GYtOE8AuYelpUpTUB58aej+GHXVfwWYhrX8NFoBMIi45GelfM90e7ufWXJcZy49Qhtv92H309G4MWfjgIAIh+n4s2fTyJw/mGdywSAxcE3sPDgDby08BgA4FzEE9yPf1qg3K5L0Wj33T58888VpGVm473VZ/H+7+dw5UHhO0gBYGnwTWw4cw+jVp7OW59817/65p/LeOfX08U+ozJLz2c6dfNF2U5de3OQ8uy303veYfx04AaCdvwrvbbo4A18tC4Uf569h7/O3ccnG88XWHa2Ruj82+TXa+4h+H2/v8Tj8Io7Fum77Vfw89Hb0uecn3Wlond7/kEH0Gf+kWKtT/vv9uPFn47imlaX/+RNF/Dz0dvoOeeQ3vlyD5RytzFbw+7j043nkaFjQH90QhpGrDiFr/++DP+gAxi75qzs9UPXHuLNn0/C7/v9BebV5XkPToJ2/IuP1oWa5IFqLoYbA6pUgqN6Qzj++Qv4+qVmBabbW1dC7o414Wkmbj3MC13aNTxwNQZ+3+/D0etx0rSRK09jS9h9ROs4Avh2+786w1Gw1hFnrq6zD+KXo7cLrf+MbVfw8uLj6DVP/wYAAM7efYIm03bhe62NrS4vLTyG5tN367wC8opjd9Dvf0ek5ml9Ip/tFF9ZfByvLQ3BlrD7ste1P+I7j1KLfQSbWUS3VHB4LG49TEZmtgZz915DeEyS7O93Jy5F9l5PS9hKePl+gtSCkSs9KxvZGoGM52h9mbntCoYuC8G2Cw/wn19OFnnk+DQjW+cGMeFpJiZtCMOW0Ps65pKLSngqjQF7EP8UGo3AssO3MGjRMXywNieQW+T7nr7725kCy4lNyvue6AvF2uEkPDoJgxcfR6dZBwqUm7Uz57u56vgdpGrthKMTC+4ctddfCCDyScEy8utfCaw8dgf7/o1FaKT8M4x4lIolwTeRpNXKEnLzEVp8vQfrTxcMwNq/dQBQaW0Rrscmy74jYZF5rRGzd4djS9gD/HPhAfT5ZON5dJp1oNCLdGo0eS1SR2/EITNbg01n7+FBESFi9u6raDJtl+zaQDdik3DqdsFxQpfu531mur5r2uGhqPctKpxqO6mjLrfiUhCr5zdhoVLhf/uvw+/7/XgQ/xQT14Vh49l72BpW8DcwbeslHLr2EKuO3wEA7L0SI3s9/+eqz/WYJJy89Ug6OPn9xF0IIUrU6yBEzu9tS9gDXDXhs/0YbgzI0qJ8/5zuTnY6w0YtJzvZ84nr8lpgTtx6hD+f7STfXnUGMYnp0jiaXH+eva9zo7D7UrTOeszfd71E9RYCWH3iLlYeuwNAvpPJeV3+3rmhZvnhW7h0PwHpWdnQaATO3HmM1IwsRCfkbDyuROVsiHQ14y8JzmmK//u8/o0zAKQ9O/LPHSO0OfQBrsck4d9ny7bM9/f+dvu/OH5TvmHJzNbgrZ9P4oedV6Vp2RqBhNRMnX/Xk7ceYeTK03hhziHZ+IqU9CxEPk7FiqO30f3/gmVHy7lBOiNLg0UHb+DivQTpuS4qlbwZ/GFSOnrMDsbARUf1zqNLtkbgI63vE5CzUZ+wNhRHrsdJgeybfy4jYO4hqTUAyAklTabtwpjf5EedADBnTzj+OncfH60PK/RoMDEtE/5BB+D77T6cvPUIHWcdwIfrQvHL0Zwd6p5nG/383Ye6BuvbaB3Ba4eyf84/wM9HCu6g9Y3fOXo9Dnce5bUUabca6cqN2o0v8U8zsFlHoNP+E9zUOjh5mpG3wBO3HqHr7IP4YddVzNx2RZo+ds1ZPM3MlrpftFnk+7vk33y8suR43mtSXfIqox3cVofcwdw9ea1Auevx3Y5/ZZ+7EALz913D5tB7uBWXty7J6VlYfvgWPtl4XmoZA4Blh25iXb6WyUUHc1pUv92et54Bcw9jyLIQ6YBEl0GLjhXa2qXdOp1Lu4tJO2QWdeyq9330zGdpocLcvdcQm5SOaVvzLvT5JDUDW8Pu48stF7E17D5S0rOK1YKUKzohDU2+2oV6n2+XHXhmZmvQa95hDF1+Qpp2JSoRE9aGosm0XYhKeIqdF6MwcNGxQocaaB8M6eoeM5XhGSZx40x6Pq/61pYd1U/t10TWX35ba4MS9GyH27yWWu/yhOzqO3keGeh07p8LadGZt/caNpyJxJbxneDiaAtA3sSe29Tcv6Ubtl/IG9MwfUDeXeGzn+3EUzOyMOa3MxACSMss3g48PV+5hKeZ6DUvp9vi0jeBOoPTG//vJHZ/1BUnbz/CG+3rIDj8IY7ekAeefv87gscpGXivW3209nDC/fg0jO7sCSDnysC5FgfflP79y9Hb2HA6Uucg8EqWOTvmlcduY/bucMzeHY6jn/XAoEXHC5QFco4StbuQ2n23DwDwICFNZ/fXv1GJOBfxBMPa1ZHtEDecicSWMP0BMStb4MddV6Xg2mz6bum1Zu6OAIB9/8YUmO++VutFlx8Pon29anB3ssMngd6ycne0vsu7LueE7W0XouDiaCMrZ1mM44zcLixA3uWRu8Pr5FVDtvNfrhV4Fh28gfE9vCCEwFu/nJQtd9CivB11/mb/E7ceYdzv56Tn+q5erW9H+dYvJ3F+em/suRwtO2Pv2I28Fo3CrpeVP5wXRqUCzkfGY5ue1pqvng2IHeZXB9Ury//+j1MyUNmmEuJTM3A7LkXnAdDZu0+k8U5xyelYfzpCFsiauathaaFC02ffGwC4/SzoaQeuGw+T4aq2hUYI2FSylH1m5+8loP7UHXrXMX/LTMLTTFl3VqLWb6NSvoPXB/FPceha3vYgSyPwKDm9wJmUOy9GY0THegXeW3tbsu/fvBDy/Y68g6I1J/R3PyemZWLl0TsY4OMmm/7DrqtSy+7IlafRtVFNDGvnAd+6VQssQyOA7c+2PxtO38O8Z4PKP//zIv54twOAnL/16F/PQAiBFSPbIU0rYIdGPMH4tecwfUBTvNDYBcNXnMKJW49wamoAqla21lv38sBwY0DFufaJodSvWVn69/+95iMLNzUdbGThRtdF2Qo72tFoyv8Kx3P2hGNIWw8s2J+zEVx88Aa+GdgcAHAx32A9ALJgAwDf/JN3RJe7X5i86YJso6+P9oYyLUt+1HE+Ml7695oTd6UzS/LLHbex61I03upQcBxU7qmnyw7l7SDTMrMxvocXTt3Rf0aPrmAD5LXcXNbaOHf+4aDe5RR2tpqu70LfBUcA5ASvvs3d8Ne5e1j6li/2XSkYTLRtOBOpt4tHu64vLz6GWk52mDukFawrWchaWu49eYp7T3JaAT7u3UjWOql9pJgboAD5TvtxSkaBbqn8Vp+4i6+25AWL9KyCR5tRCU9lOx3t7t3Zu8MxvocXQm4W/v3KH25GrjxVrKBd2AGAzzd7CkzT/rto/3QzsjS4FpOEutXt4WBrVaClt7BuBZUKGKgV1AAgNCK+QLl/oxLx9ip5t9//9l/HmbtPZAdW+W06ew8NnatIz/O3NA1YmBMy3utWX5qWkpGNAT8dxbpnO14gJ4C0/HoPqlW2RvCn3WXfs6I8zczG0GUhqGSpwjcvNSvw2WgHFe3v6P5/YzD6V/k6azQC8/ddx4Gr8m766X9fRps6VdGitlrWovW8ZvxzBZvO3sPSQzdl3dT383VzHr72EIev6R6Urq9b/UpUIs7efQLfulXxMCldWifvr3bJWnpzA+7bq85ghH9dHHnWPbbnSjSGtqtT+pUzAIYbAxFCyI66y9qa0X6Fvl7U8dnX/+g/DTH+aSY2nyt67IMh/XTgBn7SOtUyI1uDjWciUdmmUonvuZWcloWfj9zCtgu6z1ZZdPAGbK0s0ae5K2o52WHUKq2BnBrovedPcfq1j998hONF7PByzd4djp5NnKUur5KYsycc9WpULtGp6fpsLGTc0LEbj6SAOGvn1SIHpBf3lhOhEfEIjYhH5JOn+KR3I71noZ2LiEebOk7S++obmP0gIa9byT9oP2Y+C8b6aAcbIGc9b8am4LW2taVp2kFUl7TMbNzTMV5GW/KzrkWPavYAih57VVpPtAa2a4f1Rl/uBADUrW6PQ5/20DkeTR/tsSuFyR9sgMK/U9p0je3LL//ncPF+gmxA/cR1YQCA+/FP0fCLncV6X225Y2XyD7TP72lmtnTSQv5gA+R0x+nzz4UH2H05Gvee6D+oLKncYJJ//N2pUl6vKPdkCiCnBeuVJcex66MusNZqBi2sC/tXrZbhvVdi8ZqvR4Fu0PKkEqY83LkMJCYmQq1WIyEhAY6OjkXPUExpmdlo/NUuva83qFkZNpUspXEhz+vOrP6y5/U+3y577XZcCnr8X7BB3ssYKlmoyuXCdxvH+uO1pXkXGPR2cUC4jgsdAkCNKtaISzbslVz7NnfFTj1jmUxNjSo2cHG0KdGRsSEsebMN+rbIaXrvGLRfFmQM7de322NEMe+tVdnaEinFPINnxsBmGO5fD42+3FmiMU4l0b5eNXz5YhMMXXZC54Dzsvj+mpsJPbywsJjXx1GCH19piYxsDb7cUvKb/y54vRUGtqpl0PqUZP/NAcUGkv80xdWj28ue75vUDf/Rcdp2SXm7OOCtDsZt7isP5XVF3y/zjXl4lKL/yLYsdgwVJdgAOeMiyjvYAMD7z8aopGVml2mwAVDsYAOg2MEGAKZtvYwTtx6VWbABco7YX1p4TO+ZdAw2z8+cgg0A/Lj7aqmCDZDXomYs7JYykPxjNbo0rAmVKq//21C3HNj9367FKldxb3BQvvK30lTkW0Mo2T/nH+g8s6UieV3rLBWiiqAiB2K23BiIrkGCVsU5ZcNArMvxvZTsYVLxxyRQ+anowYaIyhf3iAai69z+395uDyd7Kyx4vRUAoGfjnDt1N3KpUqBsYd7u5InBbWph1uAWesvYWMk/SjZAEFF5+rJ/E2NXgUjCbikD0RVuOtSvjtCvekldHc6OtrjwdW/YW1nCq4Sj+ucOaVXo6zaVLJEEw51mSBVT6zpOOk/XJSprjV0Nd4IG0fNiy42BONjqzon5x3A42lqhkqUFqpfgAkdRCUVfndLOOl/LzXOOuinO/Veexxt+yh8UXVz1qtsbbFmtPQpeqEubn2c1g70XkbaS3FS2uGYOLHh7mfzOfhmAP9/vWGQ5Rz3baENwdrApupDCvPPsIqSmiuHGQLycHUpUfnUh16n5Z0Jn2fNXfWvrKZknsKkrAMD12VV9nzecFHaFgPy3dyiNrwc0Q40qxd8geLuU7O+bn/aFwEyNZ43KRRcqphefXa20io3uDbmd1k1VqeL4Y0yHoguVg+qVrfXehqCSpeHDzVsd6qKqvZXe19vVq4rqVWxgVYz3PjL5BXg5l2xIQHGd+iKgTJZrytR2+j8XU8BwYyTalxTPr0Vt+a0RejZxKXJ5nwR6I2hwC2wen3MEo68lqTDaocqzRuUCG5VRneph5ah2CCpk7E9xWVmq8Nf7HdG1Uc1ila9auWQ/pCFtayP0q17S8/4t3AopXbq/l6GkZ2mwb1I3dGlYQxYcO3vVkP7dpWENXbMW0KZOVez5b1ccn/KC7vcq5m0oiuuLfnnjLAa1ci/VMuxLGbjyHwQ8j/e6Gjb8tvJwwohiXPrh1Bc9i7U8/wbVn7tlpKTz//Z2e/w0rLX0/IMXvHDs8xfwt56/u64bB/8yoq3Oso62lTCmS9FH/iqVCvsmdcNvb7fX+zpQdEt1/xZuUBcSkkyVvjA2rnsDLPuPb6mXq+9zKa5h7esUGOdZp5rhWqANgeHGRNV91lXRr4VrscrbWlliWPs6cFPn7BxLs8PQDlWdvGpI9y/K1crDCT28nWVngWnfBqIkVCoV6lS3l208teXvPtHXElGYqpWt8cMrLTC2WwO0KOReWp29amCUjnu/AMDVmX2kgeBlJUsj4OVcBatH+2HjWH9p+qhOeXXq3bTogJurkYsDHG11b8gNfXT9QpO8v42TvTWm9msMJ3srvFlIt+PYbg1kG9fDk3uU6D0PfNwNm8d1RIvaanya795TujR1c4Rnjcp6W+8aOlfBlH6FD4YtacvhlvGd0LpO4V2EAODsYFtkmdeetdyemtoTP77aEuen98bVmX3wca9GhW4ftozvJHte0m2Cf4PqGOCTF1itLS1ga2Wp97dYycJC1j3zRb8mBQ7UVo9uj6n9GmP7h10wuE3RLdIAUL2Kjd6DoNw81dTdEf71q+s8CPiyfxPMGeIDoHSXyND1N367kydG6tlm6HJyavFCbH77JnXTOX1Y+zpo5eFU5PxN3RxxZUYg+jaXr0M1rWERxz5/AVdmBBa7TitHtsP0AU1hU0n+fWri9nyt64bGcGNicltL1r/rjyl9G+P7l0vXSlLa67W0fXZztSFtPQoEgtwLFWofTUztm7dT+LBnQ+nfnbyqS11keXUC1o7xw66PukjT9G0oV45qJ3tuoVKhQ/28wFOco2IAGNquDj7v27jQv0ePxs54t1sDDGvvUeA1WytL/DIyry75w9yqfPXMb+6zjaq2l3zccWVGIL7s3wQOtpUw7cW8m35qb3RsrfI2Hs9zGXPt5mN9LVjDS3mBSe3uy3b1quHdrg0QNq03vivke/t538bS7QiA4gXXjwLyvlse1eyl4DCuewNZOTd1zneustaOvGplKxz8pDum9G2CfyZ0xie9G8nmyf9d0+W7l3Nu56CrS/bvCZ2wb1Le9adyd7ADfNzxbtf6+Hm47qPkV4rYub/ezgNjuzXAj6+2BJCzkx/S1gNqOyvYWlnig54N8UJj/aG3lYcTbgf1w6RejTDtxaay71MuXa0t+l5ze7bu+e+XlUulAha92Ub2XDtk54SPmni3awN4VLMv8lIZxRkflttiY2mhwh/vdsDq0X6y35yfZzW806W+tO6l2SyO6+5VYNq0AU3hWMxumVd9a0s3Ac4voIn8wEnX9t5Ox+dmY2VR6GeXSyME7K0rYclb8lYe7Xuvqe2sYG+t/zf4didP/N9reX/THo2dYWtlKeviPvBxt+ce52loDDdloLjN88GfdC8w7chnOd0JrmpbvNetAZzsS39n1Qk9Cv4o9WleK6ebbO2YDjgxpSeauDli1istMLRt3g4/9wacNR1ssG9SV4RMeQEBTV1w7qte0kY0V4taTlj1ds5Ow6OaHab2a4z9k7qhY4MasrMqdDWVt6ilhr11JSloATk/0nb18jZ23wxsLu1orCxVWDmy6B2ULnNe88EI/7qoYlMJQYNbyl7Tdf8up3wbtK4Na2JIW/07KV1Hpz2bOMPeuhLe6VIf56f1lt2h3dbKEsc+fwEhU15Ac/e86bpuBGlpoZJdHqCtjrv+AjmXIMi9a3aH+tWxdXwnLNbaCQHAjCLuxaSv206InBaCmQOb6W1FcFcX3LBrb5itLC2kyyXoEjLlBbTX2tFpz6tSqWQB5+cRbbH/42449nlet5z2365FbTUmvJAXlHp410TtqoU3p3dtVBNt61XDqak9ZTdszNWytpNszF1uQLW0UGFqvyYI0NPqNq5HA53TcwU2cy0ymL/Y0g2+datiZMd6soMJh2eBUaVS4cOeDfF2Z09Z4MtVWBdz7vuuHNkO73Wtj5db51xKX19rU3pWNny1WqssVCrYWlniyOQeWD26PX7Ld9X2wsbJnJ/WG7+/I//9LX2rDSpbW+L/aYXFLE3BoDW4TW38M6EzPg30xpp8yyhqB7z8P77YONZfWlcAqKy3pap4O/PC1vNVX/kBlberA0K/6oWhbT0wc1DzZ2UKbkOsLCxkLevaB0j+9atL/9Y1dHLpW76y30TueugL+dMGNMWrvrXx1YtNsfStvO2G9vbJs0ZlCJjWnZx4KrgB1XKyw/34p+hXxPiOXPW0BpJ+/3IL9G/pVqruF30+CfTGmC718d8NYQXuVJurY4PqGN3ZE22fBQfrShZwfbYzcnawxQ+vtpTuhK19B19dG3MA+LhXI2wOvY93u9ZHtcrWBe6BpUvwJ90R/zQTg57dgfiTZ10N69/zR4OpOwDk3Ol7gI87fjl6W7qNxcpR7TBr51V8FNAQjVwc4Ka2RVQhl+fX9forhQzW7qzVxL3ojTZYePAGZr/mg5d+Oipdet/CQoUfX/VBcnoWdlzMuZXCfzrUxeoTdwsEgp6NnTGyUz3ZWBpdLTLarQOnvwiArZUFdlzMuwnokck9MG/vNYzu4olm7moMbeeBp5nZsM3XTDyuewOsPRWBSb0b4Ru7ZniUnCF953w8nLBprD9+DbmLrwq5Psm2DzrjanQSBreuhZnbr8juxA3kHM1Xsamks4l88Ztt8OfZe5gzxAdTN1/EjovRUguRZ43K6NvcFU72VrC0UGFgq1r4O+wB9uv4nrqp7WR3Os6/s5/wghdUKqBPMzc009rgvulXB7+fjMBErRbF4qpTzR4Rz+6Wrnl2KxBnR1s8iJefudjdO6+75KsXm+K3kDuY3KdxgeV981IzTP8772a17T2roUFN+XiKZu6OqOlgg+Dwh/CsURn+DarnX0wBtlaW0plCf59/IE1fpWOMip3W0fnUfo3RrZEzLtyL17lc7VbYHo2d0UOra1ZtbwV7a0uk5rv9RFqmRvZ9bvMsbHtUs5e11OWqVsgZo7rGx/Rp7oZeTV1haaHCx70aYe6+axjbTXdAbFFbXaBLDMg5MMt/VfKVI9th1KrTmNzHG72b5QT0xq4O2Byac/NgfSGmk1cNzN17Te86aJfTxzbfuBU7K8uc7vRX8w60tEPDmC6eECKnyz01I+/SH81rqXFnVn/ciE2CRzV7eH+5q8C8uerVsEeW1g1cc1vQeng7Y0rfxgjaeVV6TfvvOzrf2VFN3R2xclQ7uDjYmuSV3RluDGjHxC64+TAZrYvRF5pftcrWZTL6XG1vhRUj28lurKlt6X989Y7PyLVzYhdci0lCx0J+pLk+6NkQH5RwZ5K7w/2yfxNceZCILs/ex9JChXb1quL0nSd4vZ0HGrk44Pz03tKPsZGLA1ZotdgcmdwDH60Pw7YLURjVqeBgxd/f8cP/O3Ib73TxxN9hD4o9mBkA+rd0Q/+WOaH1t9F+mPLXBUx7Me80VUuLvI3U1H5N4Kq2RWAz+RG7m5MtujQs/nsCORtjAKhWOW8sg0c1e8wd2kp6rlKpdDYrT+7TGJ/09pZ2OA75Pue29apJoVaf5rXUUsvSmC718VvIXfRr4YavXmyCzGxRaBjv18JNCvo/vuqDl1vXlrpsVCpVgaZy7W6KQ592x/S/L0stAW3qVEWvpi46T5u3t66ETwMLBopvBzXH530bF1hvIGfndTU6CS/raFkb260BJvZsiCbTcnYQ2mcearQOhetWt8fCN/KOZEd39iywA8g1omM9xCalYdHBnDsv6zot+SUfd7z3bGcihCjxDkP7Wlu+OlrxXB1t8O+zjPxu15z30b4i997/dsWeKzF4u5NnkWfVhUzpiTN3HqNro5rou+AI7j1JlQLu3v92RcTj1CLHhDjYWmH9ux0w9NltKd7v3gAuDjZoVsj4uNyW3gkveGF4x3ol3mYGDW6Bz/68gDZ1qkr3ierR2Bn/zugjW+dKWr9nfa2WvnWr4s/3/eHxrOVvXPcGWBx8Ewteb4UBLd3xIOEpLj9IlMbLveTjLguguX+DXMPae+gct+JbtyrWnMi5C/oX/fNaaLTrmJu/8p+1qx32/xrXEVHxaWjs6ojYpLyDPH0DzZe+1abIk1l6eOeF3sK6toyBdwU3stzQseiNNtLOsywcuf4Qf4c9wAAfd3y7/QquxSQDAG5+369Mrk9hKGmZ2bj3JLXYp9oLIZCcnqVzh1Yc+e+uXlx34lIw4KejGN6xboEd7dJDN7HuVAQ2jPUv1gBSXTQagRnbrqB5LXWxLg1QGtrr7mRvhW9ealbgrr5pmdmwqWRRJkdqEY9SMWRZCEZ39sQYA5+9lF9KehZuxCajZW21tC5XoxNx9HocRnSsBytLC2w4HYllh2/ilxHtpAAek5gGv+/355Sf2UfnOJbC5P6NX2jsLAXzq9GJOHbjEUb41y0wiL8kXvi/YNyKSwGg+7t770kq3l9zDm93roeXW+d8h4QQWHjgBrxdHaRWi5LK1ghkZGlKfZmBO3EpOHA1Fm/41Snx37O0hBD46cAN1KtRGS/56B5GsOF0JLKFwLD2ddD5hwO49+Qp+jRzxX/86+psjRFC4Elqpt4WqaxsjXTx1q8HNEXXRjWRmpGNF386CgAI/7ZPgUG6QM5vf3PofbSu44T6Wq19Qgh4Tslp2f5rXEe00eoSvBqdiM3n7mNcdy+9Z4kdDI9FZetKsi7f8OgkBM4/DLWdFc5P761zPn2iEp5i5IrTaOruiH+jEjFjYHPZsg2hJPtvhhsjG7b8BC7ci8eJqT1LvUMuqaPX4/DWLycBlGwHbg7+Pv8AH/4Ris/7Ntbb5K1PVrbmuXZOxrb7cjSOXH+IaS82K/OLOOpTmhaL8vbttiuws7bEx72LPlMrvxZf70ZSWhZmDGyG4f71DFqv8OgkfPPPZUzq1ajIFjkqmfSsbCQ+zZJaUkvr5sNkXI1KQr8WrlCpVLh0P0EKNze+61vi7UduWA7+pLtsmMPz1rGmg02RLfrGwHBTCFMLN0IIZGRrdCb2snLk+kP855dTABhuiMpTTGIazt19gt7NXE26xZTKh3a4uR3Ur8TBfsfFKDxOycBbHUp3tmNFU5L9t2l1kpkhlUpVrsEG0H3mDRGVPRdHW/Qt5gkHpHy1q+adPFCaFsvinrxijhhuzJCfZzX41q1a4ruTExGR4TjZW2PPf7sWONORnp9JDBBYtGgR6tWrB1tbW/j5+eHUqVOFlt+4cSMaN24MW1tbtGjRAjt27CinmipDJUsL/Pl+xwLXdSEiovLVyMUBdQx481zKYfRws379ekyaNAnTp0/HuXPn4OPjg8DAQMTG6r4uy/HjxzFs2DCMHj0aoaGhGDRoEAYNGoRLly6Vc82JiIjIFBl9QLGfnx/atWuHhQsXAgA0Gg08PDzwwQcf4PPPPy9QfujQoUhJScG2bdukaR06dECrVq2wdOnSIt/P1AYUExERUdFKsv82astNRkYGzp49i4CAvNvFW1hYICAgACEhITrnCQkJkZUHgMDAQL3liYiIyLwYdUBxXFwcsrOz4eIivwqii4sLrl69qnOe6OhoneWjo6N1lk9PT0d6et5VOBMTE5+z1kRERGTKjD7mpqwFBQVBrVZLDw+Pgnd+JiIiIuUwaripUaMGLC0tERMTI5seExMDV1fdlwJ3dXUtUfkpU6YgISFBekRGRhqm8kRERGSSjBpurK2t4evri/3790vTNBoN9u/fD39/f53z+Pv7y8oDwN69e/WWt7GxgaOjo+xBREREymX0i/hNmjQJI0aMQNu2bdG+fXvMnz8fKSkpGDVqFABg+PDhqFWrFoKCggAAEydORLdu3TBnzhz0798f69atw5kzZ7B8+XJjrgYRERGZCKOHm6FDh+Lhw4eYNm0aoqOj0apVK+zatUsaNBwREQELrVu7d+zYEWvXrsWXX36JqVOnomHDhtiyZQuaN29urFUgIiIiE2L069yUN17nhoiIqOKpMNe5ISIiIjI0hhsiIiJSFIYbIiIiUhSGGyIiIlIUo58tVd5yx0/zNgxEREQVR+5+uzjnQZlduElKSgIA3oaBiIioAkpKSoJarS60jNmdCq7RaPDgwQM4ODhApVIZdNmJiYnw8PBAZGSkIk8zV/r6AcpfR65fxaf0dVT6+gHKX8eyWj8hBJKSkuDu7i67/p0uZtdyY2Fhgdq1a5fpeyj9Ng9KXz9A+evI9av4lL6OSl8/QPnrWBbrV1SLTS4OKCYiIiJFYbghIiIiRWG4MSAbGxtMnz4dNjY2xq5KmVD6+gHKX0euX8Wn9HVU+voByl9HU1g/sxtQTERERMrGlhsiIiJSFIYbIiIiUhSGGyIiIlIUhhsiIiJSFIYbA1m0aBHq1asHW1tb+Pn54dSpU8auUrEEBQWhXbt2cHBwgLOzMwYNGoTw8HBZme7du0OlUskeY8eOlZWJiIhA//79YW9vD2dnZ3z66afIysoqz1XR6+uvvy5Q/8aNG0uvp6WlYfz48ahevTqqVKmCV155BTExMbJlmPL61atXr8D6qVQqjB8/HkDF+/wOHz6MAQMGwN3dHSqVClu2bJG9LoTAtGnT4ObmBjs7OwQEBOD69euyMo8fP8abb74JR0dHODk5YfTo0UhOTpaVuXDhArp06QJbW1t4eHjgxx9/LOtVkxS2jpmZmfjss8/QokULVK5cGe7u7hg+fDgePHggW4auz33WrFmyMsZax6I+w5EjRxaoe58+fWRlKvJnCEDnb1KlUmH27NlSGVP9DIuzXzDUdjM4OBht2rSBjY0NvLy8sGrVKsOshKDntm7dOmFtbS1WrFghLl++LMaMGSOcnJxETEyMsatWpMDAQLFy5Upx6dIlERYWJvr16yfq1KkjkpOTpTLdunUTY8aMEVFRUdIjISFBej0rK0s0b95cBAQEiNDQULFjxw5Ro0YNMWXKFGOsUgHTp08XzZo1k9X/4cOH0utjx44VHh4eYv/+/eLMmTOiQ4cOomPHjtLrpr5+sbGxsnXbu3evACAOHjwohKh4n9+OHTvEF198If766y8BQGzevFn2+qxZs4RarRZbtmwR58+fFy+99JLw9PQUT58+lcr06dNH+Pj4iBMnTogjR44ILy8vMWzYMOn1hIQE4eLiIt58801x6dIl8ccffwg7OzuxbNkyo69jfHy8CAgIEOvXrxdXr14VISEhon379sLX11e2jLp164oZM2bIPlft360x17Goz3DEiBGiT58+sro/fvxYVqYif4ZCCNm6RUVFiRUrVgiVSiVu3rwplTHVz7A4+wVDbDdv3bol7O3txaRJk8SVK1fETz/9JCwtLcWuXbueex0Ybgygffv2Yvz48dLz7Oxs4e7uLoKCgoxYq9KJjY0VAMShQ4ekad26dRMTJ07UO8+OHTuEhYWFiI6OlqYtWbJEODo6ivT09LKsbrFMnz5d+Pj46HwtPj5eWFlZiY0bN0rT/v33XwFAhISECCFMf/3ymzhxomjQoIHQaDRCiIr9+eXfaWg0GuHq6ipmz54tTYuPjxc2Njbijz/+EEIIceXKFQFAnD59Wiqzc+dOoVKpxP3794UQQixevFhUrVpVtn6fffaZ8Pb2LuM1KkjXjjG/U6dOCQDi7t270rS6deuKefPm6Z3HVNZRX7gZOHCg3nmU+BkOHDhQvPDCC7JpFeUzzL9fMNR2c/LkyaJZs2ay9xo6dKgIDAx87jqzW+o5ZWRk4OzZswgICJCmWVhYICAgACEhIUasWekkJCQAAKpVqyab/vvvv6NGjRpo3rw5pkyZgtTUVOm1kJAQtGjRAi4uLtK0wMBAJCYm4vLly+VT8SJcv34d7u7uqF+/Pt58801EREQAAM6ePYvMzEzZ59e4cWPUqVNH+vwqwvrlysjIwJo1a/D222/Lbgxb0T+/XLdv30Z0dLTs81Kr1fDz85N9Xk5OTmjbtq1UJiAgABYWFjh58qRUpmvXrrC2tpbKBAYGIjw8HE+ePCmntSm+hIQEqFQqODk5yabPmjUL1atXR+vWrTF79mxZk7+pr2NwcDCcnZ3h7e2N999/H48ePZJeU9pnGBMTg+3bt2P06NEFXqsIn2H+/YKhtpshISGyZeSWMcS+0+xunGlocXFxyM7Oln2AAODi4oKrV68aqValo9Fo8NFHH6FTp05o3ry5NP2NN95A3bp14e7ujgsXLuCzzz5DeHg4/vrrLwBAdHS0zvXPfc3Y/Pz8sGrVKnh7eyMqKgrffPMNunTpgkuXLiE6OhrW1tYFdhouLi5S3U19/bRt2bIF8fHxGDlypDSton9+2nLro6u+2p+Xs7Oz7PVKlSqhWrVqsjKenp4FlpH7WtWqVcuk/qWRlpaGzz77DMOGDZPdhPDDDz9EmzZtUK1aNRw/fhxTpkxBVFQU5s6dC8C017FPnz4YPHgwPD09cfPmTUydOhV9+/ZFSEgILC0tFfcZ/vrrr3BwcMDgwYNl0yvCZ6hrv2Co7aa+MomJiXj69Cns7OxKXW+GG5KMHz8ely5dwtGjR2XT3333XenfLVq0gJubG3r27ImbN2+iQYMG5V3NEuvbt6/075YtW8LPzw9169bFhg0bnuvHY4p++eUX9O3bF+7u7tK0iv75mbPMzEwMGTIEQggsWbJE9tqkSZOkf7ds2RLW1tZ47733EBQUZPKX9X/99delf7do0QItW7ZEgwYNEBwcjJ49exqxZmVjxYoVePPNN2FrayubXhE+Q337BVPHbqnnVKNGDVhaWhYYJR4TEwNXV1cj1arkJkyYgG3btuHgwYOoXbt2oWX9/PwAADdu3AAAuLq66lz/3NdMjZOTExo1aoQbN27A1dUVGRkZiI+Pl5XR/vwqyvrdvXsX+/btwzvvvFNouYr8+eXWp7Dfm6urK2JjY2WvZ2Vl4fHjxxXqM80NNnfv3sXevXtlrTa6+Pn5ISsrC3fu3AFQMdYxV/369VGjRg3Zd1IJnyEAHDlyBOHh4UX+LgHT+wz17RcMtd3UV8bR0fG5DzwZbp6TtbU1fH19sX//fmmaRqPB/v374e/vb8SaFY8QAhMmTMDmzZtx4MCBAk2guoSFhQEA3NzcAAD+/v64ePGibGOUuzFu2rRpmdT7eSQnJ+PmzZtwc3ODr68vrKysZJ9feHg4IiIipM+voqzfypUr4ezsjP79+xdariJ/fp6ennB1dZV9XomJiTh58qTs84qPj8fZs2elMgcOHIBGo5GCnb+/Pw4fPozMzEypzN69e+Ht7W0S3Rm5web69evYt28fqlevXuQ8YWFhsLCwkLpzTH0dtd27dw+PHj2SfScr+meY65dffoGvry98fHyKLGsqn2FR+wVDbTf9/f1ly8gtY5B953MPSSaxbt06YWNjI1atWiWuXLki3n33XeHk5CQbJW6q3n//faFWq0VwcLDsdMTU1FQhhBA3btwQM2bMEGfOnBG3b98WW7duFfXr1xddu3aVlpF7yl/v3r1FWFiY2LVrl6hZs6bJnCr98ccfi+DgYHH79m1x7NgxERAQIGrUqCFiY2OFEDmnNNapU0ccOHBAnDlzRvj7+wt/f39pflNfPyFyztCrU6eO+Oyzz2TTK+Lnl5SUJEJDQ0VoaKgAIObOnStCQ0OlM4VmzZolnJycxNatW8WFCxfEwIEDdZ4K3rp1a3Hy5Elx9OhR0bBhQ9lpxPHx8cLFxUX85z//EZcuXRLr1q0T9vb25XYacWHrmJGRIV566SVRu3ZtERYWJvtd5p5lcvz4cTFv3jwRFhYmbt68KdasWSNq1qwphg8fbhLrWNj6JSUliU8++USEhISI27dvi3379ok2bdqIhg0birS0NGkZFfkzzJWQkCDs7e3FkiVLCsxvyp9hUfsFIQyz3cw9FfzTTz8V//77r1i0aBFPBTc1P/30k6hTp46wtrYW7du3FydOnDB2lYoFgM7HypUrhRBCREREiK5du4pq1aoJGxsb4eXlJT799FPZdVKEEOLOnTuib9++ws7OTtSoUUN8/PHHIjMz0whrVNDQoUOFm5ubsLa2FrVq1RJDhw4VN27ckF5/+vSpGDdunKhataqwt7cXL7/8soiKipItw5TXTwghdu/eLQCI8PBw2fSK+PkdPHhQ53dyxIgRQoic08G/+uor4eLiImxsbETPnj0LrPejR4/EsGHDRJUqVYSjo6MYNWqUSEpKkpU5f/686Ny5s7CxsRG1atUSs2bNKq9VLHQdb9++rfd3mXvtorNnzwo/Pz+hVquFra2taNKkifj+++9l4cCY61jY+qWmporevXuLmjVrCisrK1G3bl0xZsyYAgeDFfkzzLVs2TJhZ2cn4uPjC8xvyp9hUfsFIQy33Tx48KBo1aqVsLa2FvXr15e9x/NQPVsRIiIiIkXgmBsiIiJSFIYbIiIiUhSGGyIiIlIUhhsiIiJSFIYbIiIiUhSGGyIiIlIUhhsiIiJSFIYbIiIiUhSGGyIyCdHR0Zg4cSK8vLxga2sLFxcXdOrUCUuWLEFqaqqxq0dEFUglY1eAiOjWrVvo1KkTnJyc8P3336NFixawsbHBxYsXsXz5ctSqVQsvvfSSsatJRBUEW26IyOjGjRuHSpUq4cyZMxgyZAiaNGmC+vXrY+DAgdi+fTsGDBgAAJg7dy5atGiBypUrw8PDA+PGjUNycrK0nFWrVsHJyQnbtm2Dt7c37O3t8eqrryI1NRW//vor6tWrh6pVq+LDDz9Edna2NF96ejo++eQT1KpVC5UrV4afnx+Cg4PL+89ARAbClhsiMqpHjx5hz549+P7771G5cmWdZVQqFQDAwsIC//vf/+Dp6Ylbt25h3LhxmDx5MhYvXiyVTU1Nxf/+9z+sW7cOSUlJGDx4MF5++WU4OTlhx44duHXrFl555RV06tQJQ4cOBQBMmDABV65cwbp16+Du7o7NmzejT58+uHjxIho2bFj2fwQiMijeOJOIjOrkyZPo0KED/vrrL7z88svS9Bo1aiAtLQ0AMH78ePzwww8F5t20aRPGjh2LuLg4ADktN6NGjcKNGzfQoEEDAMDYsWOxevVqxMTEoEqVKgCAPn36oF69eli6dCkiIiJQv359REREwN3dXVp2QEAA2rdvj++//77M1p2IygZbbojIJJ06dQoajQZvvvkm0tPTAQD79u1DUFAQrl69isTERGRlZSEtLQ2pqamwt7cHANjb20vBBgBcXFxQr149KdjkTouNjQUAXLx4EdnZ2WjUqJHs/dPT01G9evWyXk0iKgMMN0RkVF5eXlCpVAgPD5dNr1+/PgDAzs4OAHDnzh28+OKLeP/99/Hdd9+hWrVqOHr0KEaPHo2MjAwp3FhZWcmWo1KpdE7TaDQAgOTkZFhaWuLs2bOwtLSUldMORERUcTDcEJFRVa9eHb169cLChQvxwQcf6B13c/bsWWg0GsyZMwcWFjnnQmzYsOG5379169bIzs5GbGwsunTp8tzLIyLj49lSRGR0ixcvRlZWFtq2bYv169fj33//RXh4ONasWYOrV6/C0tISXl5eyMzMxE8//YRbt25h9erVWLp06XO/d6NGjfDmm29i+PDh+Ouvv3D79m2cOnUKQUFB2L59uwHWjojKG8MNERldgwYNEBoaioCAAEyZMgU+Pj5o27YtfvrpJ3zyySeYOXMmfHx8MHfuXPzwww9o3rw5fv/9dwQFBRnk/VeuXInhw4fj448/hre3NwYNGoTTp0+jTp06Blk+EZUvni1FREREisKWGyIiIlIUhhsiIiJSFIYbIiIiUhSGGyIiIlIUhhsiIiJSFIYbIiIiUhSGGyIiIlIUhhsiIiJSFIYbIiIiUhSGGyIiIlIUhhsiIiJSFIYbIiIiUpT/D5WCwU5uVYnVAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Play, Eval()"
      ],
      "metadata": {
        "id": "fAD1F2WTo18F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a list to store the results of each game\n",
        "win_rates = []\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# See the model playout games using MCTS\n",
        "\n",
        "# Load the model and optimizer\n",
        "checkpoint = torch.load('/content/drive/My Drive/MCTS in Python/MCTS_model.pth')\n",
        "network.load_state_dict(checkpoint['model_state_dict'])\n",
        "mcts.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "network.eval()\n",
        "\n",
        "# Play # games\n",
        "num_games = 50\n",
        "\n",
        "for i in range(num_games):\n",
        "    print(f\"Game {i + 1}:\")\n",
        "\n",
        "    # Initialize the game and the root node\n",
        "    game_state = game.get_initial_state()\n",
        "    root = Node(game_state, None)\n",
        "\n",
        "    #Make sure that the MCTS and the root node persist throughout each game\n",
        "    mcts = MCTS(network, root)\n",
        "\n",
        "    while not game_state.is_terminal():\n",
        "        # Perform MCTS simulations from the root\n",
        "        for _ in range(num_games):\n",
        "            leaf = mcts.selection(root)\n",
        "            children = mcts.expansion(leaf)\n",
        "            reward = mcts.simulation(random.choice(children))\n",
        "            mcts.backpropagation(leaf, reward)\n",
        "\n",
        "        # Choose the action that leads to the most visited child node\n",
        "        action = mcts.choose_action(root)\n",
        "\n",
        "        # Apply the action to get the next state\n",
        "        game_state = game_state.make_move(action)\n",
        "\n",
        "        # print(f\"Action taken: {action}\")\n",
        "\n",
        "    print(f\"Final reward: {reward}\")\n",
        "\n",
        "    # Append the result of the game to the win_rates list\n",
        "    # Assume a reward of 1 is a win, 0 is a draw, and -1 is a loss\n",
        "    win_rates.append(reward)\n",
        "\n",
        "# mcts.print_tree(mcts.root)\n",
        "\n",
        "# Calculate the win rate\n",
        "win_rate = win_rates.count(1) / num_games\n",
        "\n",
        "# Print and plot the win rates\n",
        "print(f\"Win Rate: {win_rate}\")\n",
        "plt.plot(range(1, num_games + 1), win_rates)\n",
        "plt.xlabel('Game')\n",
        "plt.ylabel('Win Rate')\n",
        "plt.title('Win Rate per Game')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HSZiIDvchSf",
        "outputId": "5d25183d-ea02-48d8-a1e2-59ea4b1f46dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Game 1:\n",
            "Final reward: -1\n",
            "Game 2:\n",
            "Final reward: 1\n",
            "Game 3:\n",
            "Final reward: -1\n",
            "Game 4:\n",
            "Final reward: -1\n",
            "Game 5:\n",
            "Final reward: -1\n",
            "Game 6:\n",
            "Final reward: -1\n",
            "Game 7:\n",
            "Final reward: -1\n",
            "Game 8:\n",
            "Final reward: -1\n",
            "Game 9:\n",
            "Final reward: -1\n",
            "Game 10:\n",
            "Final reward: -1\n",
            "Game 11:\n",
            "Final reward: 1\n",
            "Game 12:\n",
            "Final reward: 1\n",
            "Game 13:\n",
            "Final reward: -1\n",
            "Game 14:\n",
            "Final reward: -1\n",
            "Game 15:\n",
            "Final reward: -1\n",
            "Game 16:\n",
            "Final reward: -1\n",
            "Game 17:\n",
            "Final reward: -1\n",
            "Game 18:\n",
            "Final reward: -1\n",
            "Game 19:\n",
            "Final reward: -1\n",
            "Game 20:\n",
            "Final reward: -1\n",
            "Game 21:\n",
            "Final reward: 1\n",
            "Game 22:\n",
            "Final reward: -1\n",
            "Game 23:\n",
            "Final reward: -1\n",
            "Game 24:\n",
            "Final reward: -1\n",
            "Game 25:\n",
            "Final reward: 1\n",
            "Game 26:\n",
            "Final reward: -1\n",
            "Game 27:\n",
            "Final reward: -1\n",
            "Game 28:\n",
            "Final reward: 1\n",
            "Game 29:\n",
            "Final reward: 1\n",
            "Game 30:\n",
            "Final reward: -1\n",
            "Game 31:\n",
            "Final reward: -1\n",
            "Game 32:\n",
            "Final reward: -1\n",
            "Game 33:\n",
            "Final reward: 1\n",
            "Game 34:\n",
            "Final reward: -1\n",
            "Game 35:\n",
            "Final reward: 1\n",
            "Game 36:\n",
            "Final reward: -1\n",
            "Game 37:\n",
            "Final reward: -1\n",
            "Game 38:\n",
            "Final reward: 1\n",
            "Game 39:\n",
            "Final reward: -1\n",
            "Game 40:\n",
            "Final reward: 1\n",
            "Game 41:\n",
            "Final reward: 1\n",
            "Game 42:\n",
            "Final reward: -1\n",
            "Game 43:\n",
            "Final reward: -1\n",
            "Game 44:\n"
          ]
        }
      ]
    }
  ]
}